{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kabilan942/Natural-Language-Processing/blob/main/Legal%20Document%20Summarization/Extractive_Summarization_(Legal_Domain).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxXpd63rlJOB"
      },
      "source": [
        "## Modules Required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPUYvkJIn5eo"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install rouge\n",
        "!pip install rouge_score\n",
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install nltk\n",
        "!pip install datasets\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "00f9149652ab4aefbc318d606d904f15",
            "6bba55743c144ea1a7b8390f56fb852b",
            "33526fc4e6ba49f5a6a7b9ada16da219",
            "a939cb5f93224651b5728591547ae017",
            "828ad65284374a52add02407a31443a9",
            "5103e240d3474ad88d4f000a85f4714a",
            "24fafb7f362246fea8d6000c8ce42826",
            "feab39eaf5ce481f8484e0918d785fa5",
            "97e279d486bb4d0bae7bb10b4c6313ec",
            "219210896bc74b8786a8f520ab7a1c3c",
            "9be2e04902bf4a3e8df73fb24a16df9c"
          ]
        },
        "id": "6MWft3xGlOPo",
        "outputId": "70c06d69-2114-45d3-ff5b-5949464a8d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00f9149652ab4aefbc318d606d904f15"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from rouge import Rouge\n",
        "from datasets import Dataset, DatasetDict, load_dataset, load_metric\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from nltk import tokenize\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, '../')\n",
        "from IPython.display import display, HTML\n",
        "#from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "#from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "import evaluate\n",
        "rouge_score = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrmnjBlNyziZ",
        "outputId": "2164189e-8dba-4ad0-c0d2-d20399c07890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorfl (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorfl\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorfl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHYJmB40yr_I"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, TFBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b1bd0959a55d42978b7842e0b5efba44",
            "7eb836cc1b6a43b2841a288426de7550",
            "a9e5035720db486db1046b991c244b9a",
            "ae885e445fd6499bb5dde2625f9595b9",
            "2579ae4c3ccc4ae5ae0264dfc861e6c3",
            "ea2002f4e221493ea8947496d2c2f2ec",
            "f3b313eecd1e44a08540f6913750ba53",
            "68b257af763f4ef991b69f40437d29a2",
            "d2e08a4c77fe4fbb85f2f56aa0c3d39a",
            "4c70f0e494d84fef8bb9a833a831695b",
            "2e15ef89283a41548619ea1c8e4afcca",
            "994d2c30434e417498fbdf3c288881b1",
            "3b3cdd764f92446cbfe1be1a1190d724",
            "7bd0e33b4d8b44f8b717a03461df597a",
            "0373cc5ba6384ab4998cbc3642f0963d",
            "2517f3ba997e4cdba09838affb1d6137",
            "013956f03f2a43fdb7376afc579fa38f",
            "d07e8da39ebb4d01b6cc07c6195d6f3b",
            "cf8011b4e04a4ad4996355d989e695cd",
            "bd58341fdbe446db9651a18526e155f6",
            "2f455acf62364fc1909e19e0d79a7c72",
            "df45b13661434c9d931b42d7dda1a394"
          ]
        },
        "id": "wycW9QOAy1T0",
        "outputId": "9fa4b9f8-d807-44b0-fd1e-7d6b05b125c4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1bd0959a55d42978b7842e0b5efba44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "994d2c30434e417498fbdf3c288881b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model = TFBertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNUdIYK2zDRT",
        "outputId": "257456b3-536c-48b7-fc8b-788ffad5e11b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.8.4\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.13\n",
            "albumentations                   1.2.1\n",
            "altair                           4.2.2\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      21.3.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array-record                     0.4.0\n",
            "arviz                            0.15.1\n",
            "astropy                          5.2.2\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.2\n",
            "attrs                            23.1.0\n",
            "audioread                        3.0.0\n",
            "autograd                         1.6.2\n",
            "Babel                            2.12.1\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.11.2\n",
            "bleach                           6.0.0\n",
            "blis                             0.7.9\n",
            "blosc2                           2.0.0\n",
            "bokeh                            2.4.3\n",
            "branca                           0.6.0\n",
            "build                            0.10.0\n",
            "CacheControl                     0.13.1\n",
            "cachetools                       5.3.1\n",
            "catalogue                        2.0.8\n",
            "certifi                          2023.5.7\n",
            "cffi                             1.15.1\n",
            "chardet                          4.0.0\n",
            "charset-normalizer               2.0.12\n",
            "chex                             0.1.7\n",
            "click                            8.1.4\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.25.2\n",
            "cmdstanpy                        1.1.0\n",
            "colorcet                         3.0.1\n",
            "colorlover                       0.3.0\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.0\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.1.0\n",
            "convertdate                      2.4.0\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda11x                     11.0.0\n",
            "cvxopt                           1.3.1\n",
            "cvxpy                            1.3.2\n",
            "cycler                           0.11.0\n",
            "cymem                            2.0.7\n",
            "Cython                           0.29.36\n",
            "dask                             2022.12.1\n",
            "datascience                      0.17.6\n",
            "datasets                         2.13.1\n",
            "db-dtypes                        1.1.1\n",
            "dbus-python                      1.2.16\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "dill                             0.3.6\n",
            "distributed                      2022.12.1\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docutils                         0.16\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.8.1\n",
            "earthengine-api                  0.1.358\n",
            "easydict                         1.10\n",
            "ecos                             2.0.12\n",
            "editdistance                     0.6.2\n",
            "en-core-web-sm                   3.5.0\n",
            "entrypoints                      0.4\n",
            "ephem                            4.1.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.3.0\n",
            "etuples                          0.3.9\n",
            "evaluate                         0.4.0\n",
            "exceptiongroup                   1.1.2\n",
            "fastai                           2.7.12\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.17.1\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.1\n",
            "filelock                         3.12.2\n",
            "Fiona                            1.9.4.post1\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      23.5.26\n",
            "flax                             0.7.0\n",
            "folium                           0.14.0\n",
            "fonttools                        4.40.0\n",
            "frozendict                       2.3.8\n",
            "frozenlist                       1.3.3\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.4.0\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.3.2\n",
            "gdown                            4.6.6\n",
            "gensim                           4.3.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.17.3\n",
            "google-auth-httplib2             0.1.0\n",
            "google-auth-oauthlib             1.0.0\n",
            "google-cloud-bigquery            3.10.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.22.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.1\n",
            "google-cloud-language            2.9.1\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.2\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.5.0\n",
            "googleapis-common-protos         1.59.1\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.1\n",
            "greenlet                         2.0.2\n",
            "grpc-google-iam-v1               0.12.6\n",
            "grpcio                           1.56.0\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.2.0\n",
            "h5py                             3.8.0\n",
            "holidays                         0.28\n",
            "holoviews                        1.15.4\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.0\n",
            "httplib2                         0.21.0\n",
            "huggingface-hub                  0.16.4\n",
            "humanize                         4.6.0\n",
            "hyperopt                         0.2.7\n",
            "idna                             3.4\n",
            "imageio                          2.25.1\n",
            "imageio-ffmpeg                   0.4.8\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib-resources              6.0.0\n",
            "imutils                          0.5.4\n",
            "inflect                          6.0.5\n",
            "iniconfig                        2.0.0\n",
            "intel-openmp                     2023.1.0\n",
            "ipykernel                        5.5.6\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.4.1\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.1.2\n",
            "jax                              0.4.13\n",
            "jaxlib                           0.4.13+cuda11.cudnn86\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.2\n",
            "joblib                           1.3.1\n",
            "jsonpickle                       3.0.1\n",
            "jsonschema                       4.3.3\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.3.1\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab-pygments              0.2.2\n",
            "jupyterlab-widgets               3.0.8\n",
            "kaggle                           1.5.15\n",
            "keras                            2.12.0\n",
            "kiwisolver                       1.4.4\n",
            "langcodes                        3.3.0\n",
            "lazy_loader                      0.3\n",
            "libclang                         16.0.0\n",
            "librosa                          0.10.0.post2\n",
            "lightgbm                         3.3.5\n",
            "lit                              16.0.6\n",
            "llvmlite                         0.39.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "LunarCalendar                    0.0.9\n",
            "lxml                             4.9.3\n",
            "Markdown                         3.4.3\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.3\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.6\n",
            "matplotlib-venn                  0.11.9\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.8.1\n",
            "mkl                              2019.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   9.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.5\n",
            "multidict                        6.0.4\n",
            "multipledispatch                 1.0.0\n",
            "multiprocess                     0.70.14\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.9\n",
            "music21                          8.1.0\n",
            "natsort                          8.3.1\n",
            "nbclient                         0.8.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.9.1\n",
            "nest-asyncio                     1.5.6\n",
            "networkx                         3.1\n",
            "nibabel                          3.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.4.8\n",
            "numba                            0.56.4\n",
            "numexpr                          2.8.4\n",
            "numpy                            1.22.4\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.7.0.72\n",
            "opencv-python                    4.7.0.72\n",
            "opencv-python-headless           4.8.0.74\n",
            "openpyxl                         3.0.10\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.1.5\n",
            "orbax-checkpoint                 0.2.7\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        23.1\n",
            "palettable                       3.3.3\n",
            "pandas                           1.5.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.17.9\n",
            "pandocfilters                    1.5.0\n",
            "panel                            0.14.4\n",
            "param                            1.13.0\n",
            "parso                            0.8.3\n",
            "partd                            1.4.0\n",
            "pathlib                          1.0.1\n",
            "pathy                            0.10.2\n",
            "patsy                            0.5.3\n",
            "pexpect                          4.8.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           8.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     3.8.1\n",
            "plotly                           5.13.1\n",
            "plotnine                         0.10.1\n",
            "pluggy                           1.2.0\n",
            "polars                           0.17.3\n",
            "pooch                            1.6.0\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.8\n",
            "prettytable                      0.7.2\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus-client                0.17.1\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.39\n",
            "prophet                          1.1.4\n",
            "proto-plus                       1.22.3\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.6\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          9.0.0\n",
            "pyasn1                           0.5.0\n",
            "pyasn1-modules                   0.3.0\n",
            "pycocotools                      2.0.6\n",
            "pycparser                        2.21\n",
            "pyct                             0.5.0\n",
            "pydantic                         1.10.11\n",
            "pydata-google-auth               1.8.1\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "pyerfa                           2.0.0.3\n",
            "pygame                           2.5.0\n",
            "Pygments                         2.14.0\n",
            "PyGObject                        3.36.0\n",
            "pymc                             5.1.2\n",
            "PyMeeus                          0.5.12\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyparsing                        3.1.0\n",
            "pyproj                           3.6.0\n",
            "pyproject_hooks                  1.0.0\n",
            "pyrsistent                       0.19.3\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.10.1\n",
            "pytest                           7.2.2\n",
            "python-apt                       0.0.0\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.1\n",
            "python-utils                     3.7.0\n",
            "pytz                             2022.7.1\n",
            "pyviz-comms                      2.3.2\n",
            "PyWavelets                       1.4.1\n",
            "PyYAML                           6.0\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post0\n",
            "qudida                           0.0.4\n",
            "regex                            2022.10.31\n",
            "requests                         2.27.1\n",
            "requests-oauthlib                1.3.1\n",
            "requests-unixsocket              0.2.0\n",
            "requirements-parser              0.5.0\n",
            "responses                        0.18.0\n",
            "rich                             13.4.2\n",
            "rouge                            1.0.1\n",
            "rouge-score                      0.1.2\n",
            "rpy2                             3.5.5\n",
            "rsa                              4.9\n",
            "safetensors                      0.3.1\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.10.1\n",
            "scs                              3.2.3\n",
            "seaborn                          0.12.2\n",
            "Send2Trash                       1.8.2\n",
            "sentence-transformers            2.2.2\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.1\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.3.0\n",
            "sniffio                          1.3.0\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.4.1\n",
            "soxr                             0.3.5\n",
            "spacy                            3.5.4\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.4\n",
            "Sphinx                           3.5.4\n",
            "sphinxcontrib-applehelp          1.0.4\n",
            "sphinxcontrib-devhelp            1.0.2\n",
            "sphinxcontrib-htmlhelp           2.0.1\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.3\n",
            "sphinxcontrib-serializinghtml    1.1.5\n",
            "SQLAlchemy                       2.0.18\n",
            "sqlparse                         0.4.4\n",
            "srsly                            2.4.6\n",
            "statsmodels                      0.13.5\n",
            "sympy                            1.11.1\n",
            "tables                           3.8.0\n",
            "tabulate                         0.8.10\n",
            "tblib                            2.0.0\n",
            "tenacity                         8.2.2\n",
            "tensorboard                      2.12.3\n",
            "tensorboard-data-server          0.7.1\n",
            "tensorflow                       2.12.0\n",
            "tensorflow-datasets              4.9.2\n",
            "tensorflow-estimator             2.12.0\n",
            "tensorflow-gcs-config            2.12.0\n",
            "tensorflow-hub                   0.13.0\n",
            "tensorflow-io-gcs-filesystem     0.32.0\n",
            "tensorflow-metadata              1.13.1\n",
            "tensorflow-probability           0.20.1\n",
            "tensorstore                      0.1.40\n",
            "termcolor                        2.3.0\n",
            "terminado                        0.17.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.1.10\n",
            "threadpoolctl                    3.1.0\n",
            "tifffile                         2023.7.10\n",
            "tinycss2                         1.2.1\n",
            "tokenizers                       0.13.3\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.0\n",
            "torch                            2.0.1+cu118\n",
            "torchaudio                       2.0.2+cu118\n",
            "torchdata                        0.6.1\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.15.2\n",
            "torchvision                      0.15.2+cu118\n",
            "tornado                          6.3.1\n",
            "tqdm                             4.65.0\n",
            "traitlets                        5.7.1\n",
            "transformers                     4.30.2\n",
            "triton                           2.0.0\n",
            "tweepy                           4.13.0\n",
            "typer                            0.9.0\n",
            "types-setuptools                 68.0.0.1\n",
            "typing_extensions                4.7.1\n",
            "tzlocal                          5.0.1\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          1.26.16\n",
            "vega-datasets                    0.9.0\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.6\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.6.1\n",
            "Werkzeug                         2.3.6\n",
            "wheel                            0.40.0\n",
            "widgetsnbextension               3.6.4\n",
            "wordcloud                        1.8.2.2\n",
            "wrapt                            1.14.1\n",
            "xarray                           2022.12.0\n",
            "xarray-einstats                  0.6.0\n",
            "xgboost                          1.7.6\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.2.0\n",
            "yarl                             1.9.2\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.22\n",
            "zict                             3.0.0\n",
            "zipp                             3.16.0\n"
          ]
        }
      ],
      "source": [
        "pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YZS7c_iz46y",
        "outputId": "16a276e9-8a43-4298-b276-9937c81ba970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Version: 11.8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "cuda_version = torch.version.cuda\n",
        "print(\"CUDA Version:\", cuda_version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SZznNKWaLSG"
      },
      "source": [
        "## Chunking - using similarity measures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS1raynm19pH"
      },
      "outputs": [],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "from evaluate import load\n",
        "\n",
        "def saliency_score_rougef(doc, summary, alpha=0.5):\n",
        "  # takes in two inputs and returns the saliency score\n",
        "  scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
        "  scores = scorer.score(doc, summary)\n",
        "  R1 = scores['rouge1'][2]\n",
        "  R2 = scores['rouge2'][2]\n",
        "\n",
        "  return alpha * R1 + (1 - alpha) * R2\n",
        "\n",
        "def saliency_score_rouger(doc, summary, alpha=0.5):\n",
        "  # takes in two inputs and returns the saliency score\n",
        "  scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
        "  scores = scorer.score(doc, summary)\n",
        "  R1 = scores['rouge1'][0]\n",
        "  R2 = scores['rouge2'][0]\n",
        "\n",
        "  return alpha * R1 + (1 - alpha) * R2\n",
        "\n",
        "def calculate_bleu_score(reference, candidate):\n",
        "    # Convert the reference and candidate sentences into lists of tokens\n",
        "    reference_tokens = nltk.word_tokenize(reference)\n",
        "    candidate_tokens = nltk.word_tokenize(candidate)\n",
        "\n",
        "    # Calculate BLEU score using NLTK's sentence_bleu function\n",
        "    smoothing_function = nltk.translate.bleu_score.SmoothingFunction().method1\n",
        "    bleu_score = nltk.translate.bleu_score.sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "    return bleu_score\n",
        "\n",
        "def saliency_score_bleu(doc, summary):\n",
        "  # inputs: (doc[reference_sentence], summary[candidate_sentence])\n",
        "  # output: bleu score\n",
        "\n",
        "  return calculate_bleu_score(doc, summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JepsFApt1grw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_similarity\n",
        "\n",
        "def similarity_l_l(l1, l2, metric=1):\n",
        "    '''\n",
        "    Function to find the most similar sentence in the document for each sentence in the summary\n",
        "    input:  l1 - Summary sentences\n",
        "            l2 - Document sentences\n",
        "    returns a list of document sentence indexes for each sentence in the summary\n",
        "    '''\n",
        "    if metric==7:\n",
        "      document_embeddings = sbert_model.encode(l1+l2)\n",
        "      similarities=cosine_similarity(document_embeddings)\n",
        "      print('Cosine similarity Roberta Sentence Embeddings')\n",
        "\n",
        "    if metric==6:\n",
        "      doc_summ_list = l1+l2\n",
        "      similarities = []\n",
        "      for i in doc_summ_list:\n",
        "        temp = []\n",
        "        for j in doc_summ_list:\n",
        "          temp.append(saliency_score_bleu(i,j))\n",
        "        similarities.append(temp)\n",
        "      print('BLEU Score')\n",
        "\n",
        "    if metric==5:\n",
        "      doc_summ_list = l1+l2\n",
        "      similarities = []\n",
        "      for i in doc_summ_list:\n",
        "        temp = []\n",
        "        for j in doc_summ_list:\n",
        "          temp.append(saliency_score_rouger(i,j))\n",
        "        similarities.append(temp)\n",
        "      print('ROUGE Recall')\n",
        "\n",
        "    if metric==4:\n",
        "      doc_summ_list = l1+l2\n",
        "      similarities = []\n",
        "      for i in doc_summ_list:\n",
        "        temp = []\n",
        "        for j in doc_summ_list:\n",
        "          temp.append(saliency_score_rougef(i,j))\n",
        "        similarities.append(temp)\n",
        "      print('ROUGE f1')\n",
        "\n",
        "    if metric==3:\n",
        "      document_embeddings = sbert_model.encode(l1+l2)\n",
        "      similarities=euclidean_distances(document_embeddings)\n",
        "      print('Euclidean similarity')\n",
        "\n",
        "    if metric==2:\n",
        "      document_embeddings = sbert_model.encode(l1+l2)\n",
        "      similarities=manhattan_distances(document_embeddings)\n",
        "      print('Manhattan similarity')\n",
        "\n",
        "    if metric==1:\n",
        "      document_embeddings = sbert_model.encode(l1+l2)\n",
        "      similarities=cosine_similarity(document_embeddings)\n",
        "      print('Cosine similarity')\n",
        "\n",
        "    result = []\n",
        "    for i in range(len(l1)):        # loops through all sentences in summary since first l1 sentences are summary sentences\n",
        "        vals = similarities[i]      # list of similarity of summary sentence i with all other l1+l2 sentences\n",
        "        vals = vals[len(l1):]       # considering similarity values of ith summary sentence with all other doc sentences and leaving out the summary sentences\n",
        "        idx = np.argmax(vals)       # getting the index argument of the doc sent having the highest similarity with ith summary sentence\n",
        "        result.append(idx)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVaEHK3sot7S"
      },
      "outputs": [],
      "source": [
        "def nest_sentencesV2(document,chunk_length):\n",
        "    '''\n",
        "    function to chunk a document\n",
        "    input:  document           - Input document\n",
        "            chunk_length        - chunk length\n",
        "    output: list of chunks. Each chunk is a list of sentences.\n",
        "    '''\n",
        "    nested = []  # to store list of chunks of a doc\n",
        "    sent = []    # to store sentences per chunk in loop\n",
        "    length = 0\n",
        "    for sentence in nltk.sent_tokenize(document):\n",
        "        length += len(sentence.split(\" \"))      # adding no of words per sentence\n",
        "        if length < chunk_length:\n",
        "            sent.append(sentence)  # sentences appended to sent till chunk_length is reached\n",
        "        else:\n",
        "            nested.append(sent)                 # when word limit exceed chunk length (512 for t5) add the list of sentences (a chunk) after joining to the nested list\n",
        "            sent = []                           # create a new list to store next batch fof sentences for subsequent chunk\n",
        "            sent.append(sentence)\n",
        "            length = 0\n",
        "            length += len(sentence.split(\" \"))   # added to include length i=of sentence in else loop. Initially not added\n",
        "    if len(sent)>0:                             # when all sentences are over and the chunk of remaining sentences are appended to sent\n",
        "        nested.append(sent)\n",
        "    return nested"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isOMZO2Cov50"
      },
      "outputs": [],
      "source": [
        "def get_chunks_data_from_docV2(doc, summ, m):\n",
        "    '''\n",
        "    Function to generate chunks along with their summaries\n",
        "    input:  doc - legal Document\n",
        "            summ - Gold standard summary\n",
        "    returns a list of chunks and their summaries\n",
        "    '''\n",
        "    chunk_summ_word_threshold = 15\n",
        "    sentence_mapping = {}\n",
        "    doc_sents = split_to_sentences(doc)\n",
        "    summ_sents = split_to_sentences(summ)\n",
        "\n",
        "    result = (similarity_l_l(summ_sents,doc_sents,m)) #metric = (1,2,3,4,5,6,7) = (cosine, manhattan, euclidean, Rouge f1, Rouge Recall, BLEU, cosine with roberta sentence embeddings)\n",
        "\n",
        "    for i in range(len(summ_sents)):\n",
        "        sentence_mapping[doc_sents[result[i]]] = summ_sents[i]\n",
        "    # summ_sents[i]: each sentence in the summary\n",
        "    # doc_sents[result[i]]: sent in doc corresponding to the index in result that had the highest similarity with that summary sentence\n",
        "\n",
        "    final_chunks = []\n",
        "    final_summ = []\n",
        "    for chunk in nest_sentencesV2(doc, 400):                   # divides the doc into chunks with word limit < 512 and looping through all such chunk in doc\n",
        "        summ = \"\"\n",
        "        for chunk_sent in chunk:\n",
        "            if chunk_sent in sentence_mapping:                 # if that sentence exist in the sentence_mapping keys - True\n",
        "                summ = summ + sentence_mapping[chunk_sent]     # add the summary corresponding to that doc sentence to summ\n",
        "        if len(summ.split(\" \")) >= chunk_summ_word_threshold:  # add the chunk of doc-summary pair if the word limit of summary is more that a particular threshold\n",
        "            final_chunks.append(\" \".join(chunk))\n",
        "            final_summ.append(summ)\n",
        "    return final_chunks, final_summ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MA6bDe13NJQ"
      },
      "source": [
        "**Change Path** - Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCB5zzQpxGLg"
      },
      "outputs": [],
      "source": [
        "def get_root_path():\n",
        "    '''\n",
        "    function to get root path of dataset\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    path = \"/content/drive/MyDrive/AbstractiveDataset\"\n",
        "    return path\n",
        "\n",
        "def get_summary_data():\n",
        "    '''\n",
        "    function to get names, documents, and summaries\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "\n",
        "    path = get_root_path() + '/judgement'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_source = []\n",
        "    names = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            p = filename.rfind(\"/\")\n",
        "            names.append(filename[p+1:])\n",
        "            a = f.read()\n",
        "            data_source.append(a)\n",
        "    path = get_root_path() + '/summary'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_summary = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            a = f.read()\n",
        "            l = len(a)\n",
        "            data_summary.append(a)\n",
        "\n",
        "    return names, data_source, data_summary\n",
        "\n",
        "def split_to_sentences(para):\n",
        "    sents = nltk.sent_tokenize(para)   # returns list of sentences from para\n",
        "    return sents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqKnTfS_hDGs",
        "outputId": "6fa1520a-4d28-490b-9884-cc52f4a4383a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "names, data_source, data_summary = get_summary_data()\n",
        "print(len(names))\n",
        "print(len(data_source))\n",
        "print(len(data_summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PkttoevhKfS",
        "outputId": "2894a741-a05a-4e16-fa04-d3f1a118e6fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity Roberta Sentence Embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "training_chunks = []\n",
        "training_summs = []\n",
        "doc_id = []\n",
        "metr = 1\n",
        "if metr==7:\n",
        "  sbert_model = SentenceTransformer('sentence-transformers/roberta-base-nli-stsb-mean-tokens')\n",
        "else:\n",
        "  sbert_model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
        "for i in tqdm(range(len(data_source))):\n",
        "    cks, summs = get_chunks_data_from_docV2(data_source[i],data_summary[i],metr) #metric = (1,2,3,4,5,6,7) = (cosine, manhattan, euclidean, Rouge f1, Rouge Recall, BLEU, cosine with roberta sentence embeddings)\n",
        "    training_chunks = training_chunks + cks\n",
        "    training_summs = training_summs + summs\n",
        "    for j in range(len(cks)):\n",
        "      doc_id.append(names[i])\n",
        "df = pd.DataFrame({'data':training_chunks,'summary':training_summs,'doc_id':doc_id})\n",
        "df.to_excel('chunked_mcs.xlsx')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKREfDSi_FP1"
      },
      "source": [
        "## Fine-tuning T5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcaB8AeQYlTc"
      },
      "outputs": [],
      "source": [
        "filepath = 'FD_MCS_512_3_train.xlsx'\n",
        "df = pd.read_excel(filepath,usecols='B,C')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G_N9n6wYlTd",
        "outputId": "1787ae96-0f77-4c63-9088-b778f960652c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(22, 2)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xTNlN8SxYlTe",
        "outputId": "de8d7d62-fbce-44e0-82f4-682f45168b51"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53932d15-bb09-4091-84d1-c69f41a3e3e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Civil Appeal No.94 1949. 107 834 Appeal judgme...</td>\n",
              "      <td>The charge created respect municipal property ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Accordingly, reasons indicated judgment, petit...</td>\n",
              "      <td>Romesh Thappar vs The State ( [ 1950 ] S.C.R.B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In construing Act, aim purpose, Act declared i...</td>\n",
              "      <td>The expression `` public safety '', result lon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XXXVII 1950. Application article 32 Constituti...</td>\n",
              "      <td>Neither section ( 3 ) section ( 6 ) section 4,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The law providing reasonable restrictions exer...</td>\n",
              "      <td>dissenting ) ( ) unreasonable provision contai...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53932d15-bb09-4091-84d1-c69f41a3e3e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53932d15-bb09-4091-84d1-c69f41a3e3e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53932d15-bb09-4091-84d1-c69f41a3e3e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                data  \\\n",
              "0  Civil Appeal No.94 1949. 107 834 Appeal judgme...   \n",
              "1  Accordingly, reasons indicated judgment, petit...   \n",
              "2  In construing Act, aim purpose, Act declared i...   \n",
              "3  XXXVII 1950. Application article 32 Constituti...   \n",
              "4  The law providing reasonable restrictions exer...   \n",
              "\n",
              "                                             summary  \n",
              "0  The charge created respect municipal property ...  \n",
              "1  Romesh Thappar vs The State ( [ 1950 ] S.C.R.B...  \n",
              "2  The expression `` public safety '', result lon...  \n",
              "3  Neither section ( 3 ) section ( 6 ) section 4,...  \n",
              "4  dissenting ) ( ) unreasonable provision contai...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl1sbW1e4wvF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, valid_df = train_test_split(df, test_size=0.20,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4LvtEnG481n",
        "outputId": "42874c27-da8d-42b9-f512-b4bc5b9f8df9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((17, 2), (5, 2))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape,valid_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nipula9q5S8o"
      },
      "outputs": [],
      "source": [
        "valid_df.reset_index(inplace=True)\n",
        "valid_df.drop('index',inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3kcgQ0WR54MV",
        "outputId": "ef324942-ef4b-49a4-f2da-be517d8feb7f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dbbbebd6-5902-44b0-af38-2379699c965a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>By paragraph 12, village Maruthanthanallur Gna...</td>\n",
              "      <td>5,000 A, daughter N. '' Later, provisions wish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The testator mind different situations arise c...</td>\n",
              "      <td>5 intended apply case contingency village pass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No. 37 1950. Appeal judgment Bombay High Court...</td>\n",
              "      <td>An application execution decree made expiry 12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>His darkhast attachment 856 present decree 3rd...</td>\n",
              "      <td>The decree holder contended judgment debtor ``...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The decree holder taking steps decree alive ci...</td>\n",
              "      <td>The decree holder appealed contending time Sup...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbbbebd6-5902-44b0-af38-2379699c965a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbbbebd6-5902-44b0-af38-2379699c965a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbbbebd6-5902-44b0-af38-2379699c965a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                data  \\\n",
              "0  By paragraph 12, village Maruthanthanallur Gna...   \n",
              "1  The testator mind different situations arise c...   \n",
              "2  No. 37 1950. Appeal judgment Bombay High Court...   \n",
              "3  His darkhast attachment 856 present decree 3rd...   \n",
              "4  The decree holder taking steps decree alive ci...   \n",
              "\n",
              "                                             summary  \n",
              "0  5,000 A, daughter N. '' Later, provisions wish...  \n",
              "1  5 intended apply case contingency village pass...  \n",
              "2  An application execution decree made expiry 12...  \n",
              "3  The decree holder contended judgment debtor ``...  \n",
              "4  The decree holder appealed contending time Sup...  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpxBVHS1Aoqb"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(valid_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LylxcAGvlH73",
        "outputId": "ce2524fc-512e-43e8-e6a2-c04c37b78f8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['data', 'summary', '__index_level_0__'],\n",
              "    num_rows: 17\n",
              "})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW_DTfdZDT4J"
      },
      "outputs": [],
      "source": [
        "datasets = DatasetDict()\n",
        "datasets['train'] = train_dataset.remove_columns('__index_level_0__')\n",
        "datasets['valid'] = val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjZU_YqcD9qR",
        "outputId": "9907312f-b83e-4d20-929f-bbc4475d7813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['data', 'summary'],\n",
              "        num_rows: 17\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['data', 'summary'],\n",
              "        num_rows: 5\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "cQsPRLZfiEM2",
        "outputId": "8ccce5dc-d3d8-4a67-bb48-966b5d8d5d6c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "012ce033df3b486ca9d9a50b62b855c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05478f85c20144939f0cc5ed927afcc5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/773k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9640d808131643e7b02a030267694ed8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRd-WkY7NP8s"
      },
      "outputs": [],
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 256\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  # Reviews are first tokenized\n",
        "  model_inputs = tokenizer(examples['data'], truncation=True, max_length=max_input_length)\n",
        "  # tokenizer for the target (highlights)\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(examples['summary'], truncation=True, max_length=max_target_length)\n",
        "  # The inputs are first encoded, and then the labels ('highlights') are encoded as a separate column\n",
        "  model_inputs['labels'] = labels['input_ids']\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ETVxkhzUNP8s",
        "outputId": "45746d5c-5ebb-46ea-a39e-72320793791b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2988eb429a974c58854a0fd746846f45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/17 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "088a7bfdeca1419d90dace525ff44a30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_dataset = datasets.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToeEMwvXNP8t",
        "outputId": "dd831614-e3ae-4fb4-978a-af8e836af8c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['data', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 17\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['data', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 5\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "3XRiPuOSNP8t",
        "outputId": "57d0ccd8-f740-42d3-9e20-00178d403c68"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a442e482da445ddb7075b1b37ae5b59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/231M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# Seq2SeqLM: sequence-to-sequence language modeling head\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")  # model_checkpoint = \"t5-small\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMbIArdy3eSF"
      },
      "source": [
        "**Change Path** - Path for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgU5HW6hNP8t"
      },
      "outputs": [],
      "source": [
        "# parameters of Seq2SeqTrainingArguments\n",
        "batch_size = 4\n",
        "num_training_epochs = 15\n",
        "logging_steps = len(tokenized_dataset[\"train\"])//4\n",
        "model_name = \"t5-small-finetuned-MCS-3\"\n",
        "model_dir = \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/fine-tuned_models/t5-small-finetuned-MCS-3.h5\"\n",
        "\n",
        "args = Seq2SeqTrainingArguments(evaluation_strategy='steps',\n",
        "                                learning_rate=5.6e-5,\n",
        "                                per_device_train_batch_size=batch_size,\n",
        "                                per_device_eval_batch_size=batch_size,\n",
        "                                weight_decay=0.01,\n",
        "                                eval_steps=2,\n",
        "                                save_steps=2,\n",
        "                                save_total_limit=3,\n",
        "                                num_train_epochs=num_training_epochs,\n",
        "                                predict_with_generate=True,\n",
        "                                logging_steps=logging_steps,\n",
        "                                output_dir=\"t5-small-finetuned-MCS-3\",\n",
        "                                load_best_model_at_end=True,\n",
        "                                metric_for_best_model='eval_loss',\n",
        "                                greater_is_better=False,\n",
        "                                push_to_hub=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SiGhdXSNP8t"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "rouge_score = evaluate.load('rouge')\n",
        "def compute_metric(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  # Decode generated summaries into text (summaries generated from the review_body)\n",
        "  # batch_decode -> Returns List[str]; The list of decoded sentences; Convert a list of lists of token ids into a list of strings by calling decode.\n",
        "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True) # skip_special_tokens - Whether or not to remove special tokens in the decoding.\n",
        "  # Replace -100 in the labels as we can't decode them\n",
        "  labels = np.where(labels!=-100, labels, tokenizer.pad_token_id)\n",
        "  # Decode reference summaries into text ('review_title')\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "  # ROUGE expects a newline after each sentence\n",
        "  # strip() method removes characters from both left and right based on the argument\n",
        "  decoded_preds = ['\\n'.join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "  decoded_labels = ['\\n'.join(sent_tokenize(pred.strip())) for pred in decoded_labels]\n",
        "  # Computing ROUGE score\n",
        "  # Stemming is used to remove plurals and word suffixes such as (ing, ion, ment)\n",
        "  result = rouge_score.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "  result = {key: value*100 for key, value in result.items()}\n",
        "  return {k: round(v,4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAv8fzy6NP8t"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWZx6gP6HhPW",
        "outputId": "81ef011a-01bc-4525-e125-de54103b292f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['data', 'summary'], 2)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datasets['train'].column_names, len(datasets['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhbNjhd5NP8t",
        "outputId": "c3f8bef1-20ff-4328-90c6-91b7ec162813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['input_ids', 'attention_mask', 'labels']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset = tokenized_dataset.remove_columns(datasets['train'].column_names)\n",
        "tokenized_dataset['train'].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxgXPvIqNP8u"
      },
      "outputs": [],
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "# args = Seq2SeqTrainingArguments()\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
        "trainer = Seq2SeqTrainer(model, args, train_dataset=tokenized_dataset[\"train\"], eval_dataset=tokenized_dataset[\"valid\"],\n",
        "                         data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metric,\n",
        "                         callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uCLr0AF2g5ZB",
        "outputId": "b350b45d-c8d0-4a38-b0f7-cff67e3ed9dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 17\n",
            "  Num Epochs = 15\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 75\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 02:20, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>8.766941</td>\n",
              "      <td>5.337200</td>\n",
              "      <td>0.506300</td>\n",
              "      <td>5.188900</td>\n",
              "      <td>5.188900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>7.606500</td>\n",
              "      <td>7.907529</td>\n",
              "      <td>6.464000</td>\n",
              "      <td>0.506300</td>\n",
              "      <td>5.885300</td>\n",
              "      <td>5.981000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>7.606500</td>\n",
              "      <td>7.173917</td>\n",
              "      <td>6.139400</td>\n",
              "      <td>0.506300</td>\n",
              "      <td>5.520300</td>\n",
              "      <td>5.737600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.893400</td>\n",
              "      <td>6.587154</td>\n",
              "      <td>6.139400</td>\n",
              "      <td>0.506300</td>\n",
              "      <td>5.520300</td>\n",
              "      <td>5.737600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5.893400</td>\n",
              "      <td>6.208655</td>\n",
              "      <td>5.450000</td>\n",
              "      <td>0.506300</td>\n",
              "      <td>4.956900</td>\n",
              "      <td>5.174200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>5.365500</td>\n",
              "      <td>5.998305</td>\n",
              "      <td>5.871400</td>\n",
              "      <td>0.506300</td>\n",
              "      <td>5.332000</td>\n",
              "      <td>5.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>5.365500</td>\n",
              "      <td>5.870716</td>\n",
              "      <td>5.871400</td>\n",
              "      <td>0.506300</td>\n",
              "      <td>5.332000</td>\n",
              "      <td>5.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>4.817100</td>\n",
              "      <td>5.800640</td>\n",
              "      <td>6.326900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.332000</td>\n",
              "      <td>5.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>4.817100</td>\n",
              "      <td>5.746162</td>\n",
              "      <td>6.326900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.332000</td>\n",
              "      <td>5.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>4.768200</td>\n",
              "      <td>5.699948</td>\n",
              "      <td>6.326900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.332000</td>\n",
              "      <td>5.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>4.768200</td>\n",
              "      <td>5.661960</td>\n",
              "      <td>7.190900</td>\n",
              "      <td>0.487800</td>\n",
              "      <td>6.207400</td>\n",
              "      <td>6.222400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>4.769200</td>\n",
              "      <td>5.631305</td>\n",
              "      <td>7.190900</td>\n",
              "      <td>0.487800</td>\n",
              "      <td>6.207400</td>\n",
              "      <td>6.222400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>4.769200</td>\n",
              "      <td>5.606049</td>\n",
              "      <td>7.190900</td>\n",
              "      <td>0.487800</td>\n",
              "      <td>6.207400</td>\n",
              "      <td>6.222400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>5.038900</td>\n",
              "      <td>5.583463</td>\n",
              "      <td>7.190900</td>\n",
              "      <td>0.487800</td>\n",
              "      <td>6.207400</td>\n",
              "      <td>6.222400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>5.038900</td>\n",
              "      <td>5.564998</td>\n",
              "      <td>7.190900</td>\n",
              "      <td>0.487800</td>\n",
              "      <td>6.207400</td>\n",
              "      <td>6.222400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>4.657100</td>\n",
              "      <td>5.549205</td>\n",
              "      <td>5.237400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.652600</td>\n",
              "      <td>4.652600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>4.657100</td>\n",
              "      <td>5.536311</td>\n",
              "      <td>5.237400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.652600</td>\n",
              "      <td>4.652600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>4.304800</td>\n",
              "      <td>5.527093</td>\n",
              "      <td>5.237400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.652600</td>\n",
              "      <td>4.652600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>4.304800</td>\n",
              "      <td>5.519475</td>\n",
              "      <td>5.237400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.652600</td>\n",
              "      <td>4.652600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.692800</td>\n",
              "      <td>5.511178</td>\n",
              "      <td>5.237400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.652600</td>\n",
              "      <td>4.652600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>4.692800</td>\n",
              "      <td>5.502834</td>\n",
              "      <td>5.237400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.652600</td>\n",
              "      <td>4.652600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>4.637000</td>\n",
              "      <td>5.494640</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>4.637000</td>\n",
              "      <td>5.489233</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>4.033300</td>\n",
              "      <td>5.483166</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.033300</td>\n",
              "      <td>5.478310</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>4.383900</td>\n",
              "      <td>5.472999</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>4.383900</td>\n",
              "      <td>5.468163</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>4.599300</td>\n",
              "      <td>5.463407</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>4.599300</td>\n",
              "      <td>5.459570</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>4.762200</td>\n",
              "      <td>5.455815</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>4.762200</td>\n",
              "      <td>5.452415</td>\n",
              "      <td>4.201400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.860500</td>\n",
              "      <td>3.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>4.401400</td>\n",
              "      <td>5.449512</td>\n",
              "      <td>4.150200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.454500</td>\n",
              "      <td>3.184600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>4.401400</td>\n",
              "      <td>5.447032</td>\n",
              "      <td>4.150200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.454500</td>\n",
              "      <td>3.184600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>4.627900</td>\n",
              "      <td>5.445240</td>\n",
              "      <td>4.150200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.454500</td>\n",
              "      <td>3.184600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>4.627900</td>\n",
              "      <td>5.443912</td>\n",
              "      <td>4.150200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.454500</td>\n",
              "      <td>3.184600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>4.255200</td>\n",
              "      <td>5.443129</td>\n",
              "      <td>4.150200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.454500</td>\n",
              "      <td>3.184600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>4.255200</td>\n",
              "      <td>5.442809</td>\n",
              "      <td>4.150200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.454500</td>\n",
              "      <td>3.184600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-2\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-2/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-2/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-2/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-2/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-2/spiece.model\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-4\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-4/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-4/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-4/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-4/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-4/spiece.model\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-6\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-6/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-6/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-6/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-6/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-6/spiece.model\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-8\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-8/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-8/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-8/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-8/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-8/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-2] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-10\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-10/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-10/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-10/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-10/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-10/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-4] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-12\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-12/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-12/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-12/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-12/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-12/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-6] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-14\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-14/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-14/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-14/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-14/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-14/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-8] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-16\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-16/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-16/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-16/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-16/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-16/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-10] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-18\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-18/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-18/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-18/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-12] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-20\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-20/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-20/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-20/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-20/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-20/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-14] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-22\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-22/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-22/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-22/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-22/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-22/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-16] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-24\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-24/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-24/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-24/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-24/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-24/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-18] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-26\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-26/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-26/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-26/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-26/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-26/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-20] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-28\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-28/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-28/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-28/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-28/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-28/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-22] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-30\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-30/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-30/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-30/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-30/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-30/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-24] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-32\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-32/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-32/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-32/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-32/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-32/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-26] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-34\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-34/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-34/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-34/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-34/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-34/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-28] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-36\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-36/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-36/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-36/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-30] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-38\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-38/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-38/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-38/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-38/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-38/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-32] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-40\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-40/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-40/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-40/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-40/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-40/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-34] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-42\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-42/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-42/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-42/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-42/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-42/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-44\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-44/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-44/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-44/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-44/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-44/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-38] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-46\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-46/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-46/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-46/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-46/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-46/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-40] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-48\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-48/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-48/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-48/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-48/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-48/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-42] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-50\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-50/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-50/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-50/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-50/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-50/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-44] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-52\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-52/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-52/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-52/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-52/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-52/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-46] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-54\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-54/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-54/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-54/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-48] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-56\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-56/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-56/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-56/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-56/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-56/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-50] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-58\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-58/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-58/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-58/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-58/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-58/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-52] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-60\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-60/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-60/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-60/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-60/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-60/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-62\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-62/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-62/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-62/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-62/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-62/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-56] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-64\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-64/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-64/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-64/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-64/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-64/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-58] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-66\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-66/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-66/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-66/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-66/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-66/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-60] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-68\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-68/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-68/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-68/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-68/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-68/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-62] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-70\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-70/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-70/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-70/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-70/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-70/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-64] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-72\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-72/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-72/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-72/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-66] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-MCS-3/checkpoint-74\n",
            "Configuration saved in t5-small-finetuned-MCS-3/checkpoint-74/config.json\n",
            "Model weights saved in t5-small-finetuned-MCS-3/checkpoint-74/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-MCS-3/checkpoint-74/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-MCS-3/checkpoint-74/special_tokens_map.json\n",
            "Copy vocab file to t5-small-finetuned-MCS-3/checkpoint-74/spiece.model\n",
            "Deleting older checkpoint [t5-small-finetuned-MCS-3/checkpoint-68] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from t5-small-finetuned-MCS-3/checkpoint-74 (score: 5.442809104919434).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=75, training_loss=4.849761161804199, metrics={'train_runtime': 141.2415, 'train_samples_per_second': 1.805, 'train_steps_per_second': 0.531, 'total_flos': 34512159375360.0, 'train_loss': 4.849761161804199, 'epoch': 15.0})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "jg0sohM6F09Q",
        "outputId": "9082ca3a-5d0e-498e-9847-43f81a839977"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 5.442809104919434,\n",
              " 'eval_rouge1': 4.1502,\n",
              " 'eval_rouge2': 0.0,\n",
              " 'eval_rougeL': 4.4545,\n",
              " 'eval_rougeLsum': 3.1846,\n",
              " 'eval_runtime': 0.8866,\n",
              " 'eval_samples_per_second': 5.64,\n",
              " 'eval_steps_per_second': 2.256,\n",
              " 'epoch': 15.0}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wpLzrVC-SCv"
      },
      "source": [
        "**Change Path** - Path of model saved in model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3ddCpnkCBBX",
        "outputId": "16926d11-029f-4044-f0ef-840554d9815a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/fine-tuned_models/t5-small-finetuned-MCS-3.h5\n",
            "Configuration saved in /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/fine-tuned_models/t5-small-finetuned-MCS-3.h5/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/fine-tuned_models/t5-small-finetuned-MCS-3.h5/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/fine-tuned_models/t5-small-finetuned-MCS-3.h5/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/fine-tuned_models/t5-small-finetuned-MCS-3.h5/special_tokens_map.json\n",
            "Copy vocab file to /content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/fine-tuned_models/t5-small-finetuned-MCS-3.h5/spiece.model\n"
          ]
        }
      ],
      "source": [
        "model_dir = \"/content/drive/MyDrive/Legal Data/Indian Legal Abs Ext/dataset/IN-Abs/fine-tuned_models/t5-small-finetuned-MCS-3.h5\"\n",
        "trainer.save_model(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re-RtnIeenLU"
      },
      "source": [
        "## BART Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jZw49wwf8JS",
        "outputId": "31be9fe0-1635-4312-9e7b-4ee4e9433aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.4/722.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.8/728.8 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# This run uses Pytorch Lightening to finetune the model\n",
        "!pip install -q pytorch-lightning\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMDzroRBevzg"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from nltk import tokenize\n",
        "import nltk\n",
        "import transformers\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "#Source - https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1\n",
        "class LitModel(pl.LightningModule):\n",
        "  # Instantiate the model\n",
        "  def __init__(self, learning_rate, tokenizer, model):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.model = model\n",
        "    self.learning_rate = learning_rate\n",
        "    # self.freeze_encoder = freeze_encoder\n",
        "    # self.freeze_embeds_ = freeze_embeds\n",
        "#     self.hparams = argparse.Namespace()\n",
        "\n",
        "    self.hparams.freeze_encoder = True\n",
        "    self.hparams.freeze_embeds = True\n",
        "    self.hparams.eval_beams = 4\n",
        "    # self.hparams = hparams\n",
        "\n",
        "    if self.hparams.freeze_encoder:\n",
        "      freeze_params(self.model.get_encoder())\n",
        "\n",
        "    if self.hparams.freeze_embeds:\n",
        "      self.freeze_embeds()\n",
        "\n",
        "  def freeze_embeds(self):\n",
        "    ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n",
        "    freeze_params(self.model.model.shared)\n",
        "    for d in [self.model.model.encoder, self.model.model.decoder]:\n",
        "      freeze_params(d.embed_positions)\n",
        "      freeze_params(d.embed_tokens)\n",
        "\n",
        "  # Do a forward pass through the model\n",
        "  def forward(self, input_ids, **kwargs):\n",
        "    return self.model(input_ids, **kwargs)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    # Load the data into variables\n",
        "    src_ids, src_mask = batch[0], batch[1]\n",
        "    tgt_ids = batch[2]\n",
        "    # Shift the decoder tokens right (but NOT the tgt_ids)\n",
        "    decoder_input_ids = shift_tokens_right(tgt_ids, self.tokenizer.pad_token_id)\n",
        "\n",
        "    # Run the model and get the logits\n",
        "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "    lm_logits = outputs[0]\n",
        "    # Create the loss function\n",
        "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "    # Calculate the loss on the un-shifted tokens\n",
        "    loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "    return {'loss':loss}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "\n",
        "    src_ids, src_mask = batch[0], batch[1]\n",
        "    tgt_ids = batch[2]\n",
        "\n",
        "    decoder_input_ids = shift_tokens_right(tgt_ids, self.tokenizer.pad_token_id)\n",
        "\n",
        "    # Run the model and get the logits\n",
        "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "    lm_logits = outputs[0]\n",
        "\n",
        "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "    val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "    return {'loss': val_loss}\n",
        "\n",
        "  # Method that generates text using the BartForConditionalGeneration's generate() method\n",
        "  def generate_text(self, text, eval_beams, early_stopping = True, max_len = 1024):\n",
        "    ''' Function to generate text '''\n",
        "    generated_ids = self.model.generate(\n",
        "        text[\"input_ids\"],\n",
        "        attention_mask=text[\"attention_mask\"],\n",
        "        use_cache=True,\n",
        "        decoder_start_token_id = self.tokenizer.pad_token_id,\n",
        "        num_beams= eval_beams,\n",
        "        max_length = max_len,\n",
        "        early_stopping = early_stopping\n",
        "    )\n",
        "    return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n",
        "\n",
        "def freeze_params(model):\n",
        "  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n",
        "      adapted from finetune.py '''\n",
        "  for layer in model.parameters():\n",
        "    layer.requires_grade = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfmCYNm9fZwa"
      },
      "outputs": [],
      "source": [
        "# Create a dataloading module as per the PyTorch Lightning Docs\n",
        "class SummaryDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, tokenizer, df, batch_size):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.data = df\n",
        "\n",
        "  # Loads and splits the data into training, validation and test sets with a 60/20/20 split\n",
        "  def prepare_data(self):\n",
        "    self.train, self.validate, self.test = np.split(self.data.sample(frac=1), [int(.6*len(self.data)), int(.8*len(self.data))])\n",
        "\n",
        "  # encode the sentences using the tokenizer\n",
        "  def setup(self, stage):\n",
        "    self.train = encode_sentences(self.tokenizer, self.train['source'], self.train['target'])\n",
        "    self.validate = encode_sentences(self.tokenizer, self.validate['source'], self.validate['target'])\n",
        "    self.test = encode_sentences(self.tokenizer, self.test['source'], self.test['target'])\n",
        "\n",
        "  # Load the training, validation and test sets in Pytorch Dataset objects\n",
        "  def train_dataloader(self):\n",
        "    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])\n",
        "    train_data = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n",
        "    return train_data\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels'])\n",
        "    val_data = DataLoader(dataset, batch_size = self.batch_size)\n",
        "    return val_data\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels'])\n",
        "    test_data = DataLoader(dataset, batch_size = self.batch_size)\n",
        "    return test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O427NrXfyvd"
      },
      "outputs": [],
      "source": [
        "def shift_tokens_right(input_ids, pad_token_id):\n",
        "  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n",
        "      This is taken directly from modeling_bart.py\n",
        "  \"\"\"\n",
        "  prev_output_tokens = input_ids.clone()\n",
        "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
        "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
        "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
        "  return prev_output_tokens\n",
        "\n",
        "def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=1024, min_length = 512, pad_to_max_length=True, return_tensors=\"pt\"):\n",
        "  ''' Function that tokenizes a sentence\n",
        "      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n",
        "      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n",
        "  '''\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  target_ids = []\n",
        "  tokenized_sentences = {}\n",
        "\n",
        "  for sentence in source_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=max_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim = 0)\n",
        "  attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "\n",
        "  for sentence in target_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=min_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "    # Shift the target ids to the right\n",
        "    # shifted_target_ids = shift_tokens_right(encoded_dict['input_ids'], tokenizer.pad_token_id)\n",
        "    target_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  target_ids = torch.cat(target_ids, dim = 0)\n",
        "\n",
        "\n",
        "  batch = {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "      \"labels\": target_ids,\n",
        "  }\n",
        "\n",
        "  return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6x2eBKydsae"
      },
      "source": [
        "## Fine-Tuning BART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5qREhA2du9z"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/mcs.xlsx\"\n",
        "df = pd.read_excel(filepath,usecols='B,C')\n",
        "#df = pd.read_excel(filename,index_col=0)\n",
        "df.rename(columns = {'data':'source', 'summary':'target'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "yl1z_iRigWCB",
        "outputId": "e17fc7b2-1cf2-44c7-eae0-754fe940004e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-e58e6983-7045-49bd-adc5-a8a2188269fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Appeal No. LXVI of 1949. Appeal from the High ...</td>\n",
              "      <td>The charge created in respect of municipal pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dudhuria vs Commissioner of Income tax, Calcut...</td>\n",
              "      <td>The charge in respect of urban immoveable prop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kania J., as he then was, said as follows : \"I...</td>\n",
              "      <td>The expression \"capital charge\" in s.9(1) (iv)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e58e6983-7045-49bd-adc5-a8a2188269fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e52ac128-9513-4b26-8f2c-5e5a0acfe6f0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e52ac128-9513-4b26-8f2c-5e5a0acfe6f0')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e52ac128-9513-4b26-8f2c-5e5a0acfe6f0 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e58e6983-7045-49bd-adc5-a8a2188269fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e58e6983-7045-49bd-adc5-a8a2188269fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              source  \\\n",
              "0  Appeal No. LXVI of 1949. Appeal from the High ...   \n",
              "1  Dudhuria vs Commissioner of Income tax, Calcut...   \n",
              "2  Kania J., as he then was, said as follows : \"I...   \n",
              "\n",
              "                                              target  \n",
              "0  The charge created in respect of municipal pro...  \n",
              "1  The charge in respect of urban immoveable prop...  \n",
              "2  The expression \"capital charge\" in s.9(1) (iv)...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "343bf943bedf498bb9f6e252c10eab6c",
            "658f6b1eeb3d4f40b9e9ef8281d24918",
            "ed2b35ef568b421486fb0c5fdff588cf",
            "957685d3befc48af85f7d159a701afa3",
            "9998d239f89445d0941ea73d883601f7",
            "2c216fde7be0494592363138d76eeb74",
            "e2316d64cf0e4b30aaa0f1badfd65a9d",
            "0f03962741d5463a9dd42dbd51d5fba8",
            "390d0f9dc0284726ac9ee3bebb5904d1",
            "cc9dd6d2dd6948dcbf8c9823bcbe8b8d",
            "775ec9c39b1644c591c3e0a2e5569fec",
            "b5f63014d64c4e2cad87bf54742b85c2",
            "48e91a57a23242039a6d9065b95cc0cc",
            "0c87889469fd436696be18ec99057847",
            "969d2b10603a4c75b90a6711c22bd6a6",
            "43fd64aefdea498f9e426a42b5ed7f86",
            "cb3aa40c57814ea6aae1463fafec5da7",
            "12520932ac784f13aec2bc5452370880",
            "33caefba554649e5ad6970d14385a690",
            "a85bad7ce0584070b4365e3bd60c65bb",
            "9d733fdba81742e298d13e2f0d8fba6e",
            "f4b40914eb044fb69c669b7d578d97e2",
            "e7f0810f826648c2833d107811c7b89d",
            "f3d16a5f58e84374a8a7440b754035be",
            "cadddd3f7fe04f3984c5e4cc771ec9c7",
            "96549dd0c7574a25a28409b08bd57b5b",
            "d6c045ef29eb45bcbc4355e512b986af",
            "683bf52e2f614a0aa5ba4b7eca356c47",
            "985960bcd1074f90a3c880f7bd3d077b",
            "fd64d8fadf5e41b2a1d5aeaa3c258f40",
            "e0f9751927f24605b94cd4d14b95cfea",
            "e7f859b76a8e43748e1d604ced91f09e",
            "d06e3bd592774bc68a8936ede7621cd1",
            "4ede9efd653148759649c3c6b50ef0c4",
            "0bf4795eef79446c996ea0a7cbf12fef",
            "d5cea8e955c2440f928e464008069bbf",
            "6cb190e2fef541ef817e185b674edb58",
            "1ceaddc142b44ae0be729c791361c63b",
            "a6c57d803d2f473db134997f01269445",
            "cc29d7bc0e42486e92836567a865a9b7",
            "73f1b7b3fa2a4d62921f203a780f9c88",
            "6825ff6cf0854906b3ee6a3f3a6afdec",
            "62b113271b5842a0b5c5a02d8cc66622",
            "9a2f344f94b342a5b87385c840419c5b",
            "fdc7db217c654a07a59594eb7d29c9b0",
            "5cacdf31d03d457db7d0235eb5a8c70b",
            "ce3d7e7c597c44209a10da8e10e643d3",
            "000b810d3dad49a497bdd6916a5db059",
            "a5c4912ba0e64a6ebb536a2a9230674f",
            "ce316b9263a143f8ab64e79ece81de26",
            "dbb74dd0d23c42668e9f20ba60586134",
            "e15b069413c442b7975c09e9cfe97392",
            "cd373f434ab7464fbafb9381aa7f1da4",
            "06421b7e4d49473cb23cbd783a9a41b4",
            "3d4e66587fc34a1399401c8a0ebe9521"
          ]
        },
        "id": "9_V5oSpggeSK",
        "outputId": "e086ffd9-c662-4153-b8a3-6ca0be38df65"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "343bf943bedf498bb9f6e252c10eab6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5f63014d64c4e2cad87bf54742b85c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f0810f826648c2833d107811c7b89d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ede9efd653148759649c3c6b50ef0c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdc7db217c654a07a59594eb7d29c9b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loading Model and tokenizer\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large', add_prefix_space=True)\n",
        "\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO21hrDhgeWH",
        "outputId": "fdeed767-a004-477a-8549-9c3b19c20662"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(50272, 1024)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add special tokens if required\n",
        "\n",
        "new_tokens = ['<F>', '<RLC>', '<A>', '<S>', '<P>', '<R>', '<RPC>']\n",
        "\n",
        "special_tokens_dict = {'additional_special_tokens': new_tokens}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "bart_model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kczfaOdNgeYW"
      },
      "outputs": [],
      "source": [
        "summary_data = SummaryDataModule(tokenizer, df, batch_size = 1)\n",
        "model = LitModel(learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqQmzmPLku5U"
      },
      "outputs": [],
      "source": [
        "# put in chatgpt for code implementation - \"finetuning BART model with LitModel multi GPU implementation with tensorflow\"\n",
        "# for early stopping - \"finetuning BART model with LitModel and adding a early stopping criterea with lightning module\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yl9P8-Egwyk",
        "outputId": "9cac34c1-9521-4a63-da62-95787767ea11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "# import pytorch_lightning as pl\n",
        "\n",
        "trainer = pl.Trainer(accelerator=\"auto\", # \"accelarator='auto'\" keyword which automatically uses all available GPUs\n",
        "                     max_epochs = 3,\n",
        "                     min_epochs = 2,\n",
        "                     precision = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "701c2582aec1435ea0d8d7b917dfefeb",
            "7248a75b3b28464cb3d337282670bd21",
            "9d2102b370e44e1a952de2c02fd878ef",
            "9622f0a288794e86823d7767b80f0306",
            "ffd323f93ca4416b9fe962faf3e8640c",
            "36837c1a41694878b3b0b6233aad4250",
            "5fa26c1f786a48a7a2aa9f9785caadf1",
            "7133d67addc4490dbed7629c29e7f51f",
            "cda793a53446445ea39cf84c861475c9",
            "8202feb9574949cda81385567d1a0732",
            "7f18fc2aee19427a8e6e73c70a23427b",
            "19e6a261c3c841bd98c51285c586d7f1",
            "1be19a08e990434aa0a4d8aa4bb636c8",
            "4fdce4b2e1e0447abafe75b5b7b3ae9d",
            "039f90b899ca47c7a72b44c05aa3d231",
            "e2280b37404748ac8ee987f752169a5b",
            "b84d53ebde12442da0dfd6d855c08e32",
            "d7270698670c4186ab804d5a35d2d37c",
            "319744f931c9494094e061995c2bf646",
            "a250b9f9b4a648f7b75c8730e0d45027",
            "6b0bf06a805f4828a024f3869b7711a7",
            "5164f226cc4d43fdb89ae5d529a43712",
            "1e21df12620b4339a3d415d9104c3254",
            "40716c63ca234059bbb8f0fb56cc4e1d",
            "05c9bbf29ed8423193e3266b870825ac",
            "0b19d78b971b4980bf2cea71f668e908",
            "ec820f74db204d41854f190d024d43d8",
            "019b2a2008e8431da355e7374b7a1c66",
            "d093f1d7d3544bc0b359195ed090f4f4",
            "dee9a1214315453eb0457b89362582ee",
            "0e85567675a74fcdaaf59bdc51f63b18",
            "f748bbb050494f68a00d3681c9594c0b",
            "a167fe71d31249169743e4f2f90e225b",
            "545072ee19ca498d883dba244a8ff96c",
            "b0dc6ab7b86d4c179cd815d288803c7d",
            "9a2747a5d5934d14a962f216fbd6574c",
            "f034c1ffe4f6463b8ba1df6321a9feef",
            "8f5624fe417740c5b399b493e993c46a",
            "1d633d5c31164331a252b7d6c4eefd0e",
            "0955b13fe49145de8440afad6d6c448c",
            "0d2c89406deb426596d6b79ed13f34fd",
            "a052678115c14bad88389d02264673d7",
            "3adc7241b621413f884aeaffac53385c",
            "358facabc8744a668fd1ac57a6d98653",
            "ba31edf28a624daa933aa05ec239cdcc",
            "31ebd380e9244b2e87715d1a8e6fb2b4",
            "4a842a2468ca402fb82bd3f63853c261",
            "40625ba561334f1d8cea34b98683a0c0",
            "c5781e6a87f848689679e41b2e1f7600",
            "b1d28e620505477ebf607e590aff5b61",
            "04631b1105974b6fb5005278c6458f59",
            "4397ca8104d141409052dacd05d59817",
            "6745552a8cbc432c8af7f4daf9081af7",
            "2b9e6c69b36c4e2180be94fcc663f9e9",
            "844b32fc38394caeae3340ad83f3f24a"
          ]
        },
        "id": "ces-vfNlg5dx",
        "outputId": "c0f70e82-bdab-4f63-fbe9-482c818080c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                         | Params\n",
            "-------------------------------------------------------\n",
            "0 | model | BartForConditionalGeneration | 406 M \n",
            "-------------------------------------------------------\n",
            "406 M     Trainable params\n",
            "0         Non-trainable params\n",
            "406 M     Total params\n",
            "1,625.194 Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "701c2582aec1435ea0d8d7b917dfefeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e6a261c3c841bd98c51285c586d7f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e21df12620b4339a3d415d9104c3254",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "545072ee19ca498d883dba244a8ff96c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba31edf28a624daa933aa05ec239cdcc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, summary_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH8srlzIkvhs"
      },
      "outputs": [],
      "source": [
        "#Save the model\n",
        "trainer.save_checkpoint(\"output.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYXVVTM6hVUX"
      },
      "source": [
        "## Evaluation (Extractive) of Pre-Trained BART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFAXQLmfhVUX"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate\n",
        "!pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBWLjS3hhVUY",
        "outputId": "a9a7a58c-aa31-47e6-e901-baf040daacee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../')\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from rouge_score import rouge_scorer\n",
        "from rouge import Rouge\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from evaluate import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNyW_7G6hVUa"
      },
      "outputs": [],
      "source": [
        "ext_analysis = pd.read_csv('Extractive Test Dataset Analysis.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgQanB1ohVUa"
      },
      "outputs": [],
      "source": [
        "names, summ_word_count = list(ext_analysis['File']), list(ext_analysis['L = Average Summary Word Count'])\n",
        "\n",
        "get_req_len = {}\n",
        "for i in range(len(names)):\n",
        "  get_req_len[names[i]] = summ_word_count[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxFv5w0ginV7",
        "outputId": "c8f8d103-1a63-4853-8b41-a611f9cba807"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'2012_S_270.txt': 1362,\n",
              " '2014_J_33.txt': 1007,\n",
              " '2014_R_41.txt': 1078,\n",
              " '2015_J_10.txt': 1126,\n",
              " '2015_S_368.txt': 1400}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_req_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98FW1go7hVUb"
      },
      "outputs": [],
      "source": [
        "# Loading Model and tokenizer\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large', add_prefix_space=True)\n",
        "\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0wBQ3rwlp6T"
      },
      "outputs": [],
      "source": [
        "bart_model = LitModel(learning_rate = 2e-5, tokenizer = tokenizer, model = model)\n",
        "\n",
        "# bart_model = LitModel.load_from_checkpoint(\"/home/pahelibhattacharya/HULK/Abhay/models/BART_large_IN_MCS.ckpt\",\n",
        "#                                       learning_rate = 2e-5, tokenizer = tokenizer, model = model).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxhe4AlohVUb"
      },
      "outputs": [],
      "source": [
        "def nest_sentences(document,chunk_length):\n",
        "    '''\n",
        "    function to chunk a document\n",
        "    input:  document           - Input document\n",
        "            chunk_length        - chunk length\n",
        "    output: list of chunks. Each chunk is a string.\n",
        "    '''\n",
        "    nested = []  # to store list of chunks of a doc\n",
        "    sent = []    # to store sentences per chunk in loop\n",
        "    length = 0\n",
        "    for sentence in nltk.sent_tokenize(document):\n",
        "        length += len(sentence.split(\" \"))       # adding no of words per sentence\n",
        "        if length < chunk_length:\n",
        "            sent.append(sentence)\n",
        "        else:\n",
        "            nested.append(\" \".join(sent))        # when word limit exceed chunk length (512 for t5) add the list of sentences (a chunk) after joining to the nested list\n",
        "            sent = []                            # create a new list to store next batch fof sentences for subsequent chunk\n",
        "            sent.append(sentence)\n",
        "            length = 0\n",
        "            length += len(sentence.split(\" \"))   # added to include length i=of sentence in else loop. Initially not added\n",
        "    if len(sent)>0:\n",
        "        nested.append(\" \".join(sent))            # including the final list of sentences to nested\n",
        "    return nested                                # return the list of chunks of that doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsOty1HZhVUb"
      },
      "outputs": [],
      "source": [
        "def generate_summary_gpu(nested_sentences,p=0.2):\n",
        "  '''\n",
        "    Function to generate summaries from the list containing chunks of the document\n",
        "    input:  nested_sentences - chunks\n",
        "            p - Number of words in summaries per word in the document\n",
        "    output: document summary\n",
        "    '''\n",
        "  summaries = []\n",
        "  for nested in nested_sentences:         # looping through each of the chunks\n",
        "    l = int(p * len(nested.split(\" \")))   # multiplying p with length of chunk to distribute summary length to that particular chunk\n",
        "    input_tokenized = tokenizer.encode(nested, truncation=True, return_tensors='pt')\n",
        "    summary_ids = bart_model.model.generate(input_tokenized,\n",
        "                                      length_penalty=0.01,\n",
        "                                      min_length=l-5,\n",
        "                                      max_length=l+5)\n",
        "    output = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
        "    summaries.append(output)\n",
        "  summaries = [sentence for sublist in summaries for sentence in sublist]\n",
        "  print(summaries)\n",
        "  return summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbjiYDnyhuuP"
      },
      "source": [
        "### Testing A1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMatqac7hVUZ"
      },
      "outputs": [],
      "source": [
        "def get_root_path():\n",
        "    '''\n",
        "    function to get root path of dataset\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    path = \"/content/drive/MyDrive/ExtractiveDataset/test-data\"  # use all 50 docs for testing if using abstractive dataset for training\n",
        "    return path\n",
        "\n",
        "def get_summary_data():\n",
        "    '''\n",
        "    function to get names, documents, and summaries\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "\n",
        "    path = get_root_path() + '/judgement'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_source = []\n",
        "    names = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            p = filename.rfind(\"/\")\n",
        "            names.append(filename[p+1:])\n",
        "            a = f.read()\n",
        "            data_source.append(a)\n",
        "    path = get_root_path() + '/summary/A1'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_summary = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            a = f.read()\n",
        "            l = len(a)\n",
        "            data_summary.append(a)\n",
        "\n",
        "    return names, data_source, data_summary\n",
        "\n",
        "def split_to_sentences(para):\n",
        "    sents = nltk.sent_tokenize(para)   # returns list of sentences from para\n",
        "    return sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktCH3faohVUZ",
        "outputId": "e7ea8add-1901-4585-d702-ba7ff5fa29cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "names, data_source, data_summary = get_summary_data()\n",
        "print(len(names))\n",
        "print(len(data_source))\n",
        "print(len(data_summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Qs0M8BpThVUc",
        "outputId": "107fb317-4a9a-4656-8220-c18f7438df76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 2012_S_270.txt - 4248 : 1362 ,Value of p for doc 0 is 0.3206214689265537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-26d273ff5d9a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Value of p for doc {} is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mextr_summ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# returns list of chunks summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-a3d4b3cbfec0>\u001b[0m in \u001b[0;36mgenerate_summary_gpu\u001b[0;34m(nested_sentences, p)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# multiplying p with length of chunk to distribute summary length to that particular chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     summary_ids = bart_model.model.generate(input_tokenized,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                       \u001b[0mlength_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                       \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    857\u001b[0m                     )\n\u001b[1;32m    858\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                     layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m    860\u001b[0m                         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \"\"\"\n\u001b[1;32m    332\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         hidden_states, attn_weights, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# main loop to generate and save summaries of each document in the test dataset\n",
        "\n",
        "result_rouge_list = []\n",
        "result_bertscore_list = []\n",
        "\n",
        "for i in tqdm(range(2)):  # range(len(data_source))\n",
        "    name = names[i]\n",
        "    doc = data_source[i]\n",
        "    input_len = len(doc.split(\" \"))\n",
        "    req_len = get_req_len[name]\n",
        "    print(str(i) + \": \" + name +  \" - \" + str(input_len) + \" : \" + str(req_len), end = \" ,\")\n",
        "\n",
        "    nested = nest_sentences(doc,512)  # returns a list of chunks with word count < 512\n",
        "    p = float(req_len/input_len)  # p is the ratio of summary length to doc length\n",
        "    print('Value of p for doc {} is {}'.format(i,p))\n",
        "\n",
        "    extr_summ = generate_summary_gpu(nested,p)  # returns list of chunks summaries\n",
        "    print('--------------------------')\n",
        "\n",
        "    extr_summ = \" \".join(extr_summ)\n",
        "    print(extr_summ)\n",
        "\n",
        "    if len(extr_summ.split(\" \")) > req_len:\n",
        "        extr_summ = extr_summ.split(\" \")\n",
        "        extr_summ = extr_summ[:req_len]\n",
        "        extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    print(len(data_summary[i].split(' ')),len(extr_summ.split(' ')))\n",
        "\n",
        "    rouge = Rouge()\n",
        "    result_rouge_list.append(rouge.get_scores(extr_summ, data_summary[i], avg=True))\n",
        "    bertscore = load(\"bertscore\")\n",
        "    result_bertscore_list.append(bertscore.compute(predictions=[extr_summ], references=[data_summary[i]], model_type=\"distilbert-base-uncased\"))\n",
        "    print('---------------------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF3LUl_LGXkh"
      },
      "outputs": [],
      "source": [
        "hypothesis_1 = \"King Norodom Sihanouk has declined requests to chair a summit of Cambodia 's top political leaders , saying the meeting would not bring any progress in deadlocked negotiations to form a government .\\nGovernment and opposition parties have asked King Norodom Sihanouk to host a summit meeting after a series of post-election negotiations between the two opposition groups and Hun Sen 's party to form a new government failed .\\nHun Sen 's ruling party narrowly won a majority in elections in July , but the opposition _ claiming widespread intimidation and fraud _ has denied Hun Sen the two-thirds vote in parliament required to approve the next government .\\n\"\n",
        "references_1 = [\"Prospects were dim for resolution of the political crisis in Cambodia in October 1998.\\nPrime Minister Hun Sen insisted that talks take place in Cambodia while opposition leaders Ranariddh and Sam Rainsy, fearing arrest at home, wanted them abroad.\\nKing Sihanouk declined to chair talks in either place.\\nA U.S. House resolution criticized Hun Sen's regime while the opposition tried to cut off his access to loans.\\nBut in November the King announced a coalition government with Hun Sen heading the executive and Ranariddh leading the parliament.\\nLeft out, Sam Rainsy sought the King's assurance of Hun Sen's promise of safety and freedom for all politicians.\",\n",
        "                \"Cambodian prime minister Hun Sen rejects demands of 2 opposition parties for talks in Beijing after failing to win a 2/3 majority in recent elections.\\nSihanouk refuses to host talks in Beijing.\\nOpposition parties ask the Asian Development Bank to stop loans to Hun Sen's government.\\nCCP defends Hun Sen to the US Senate.\\nFUNCINPEC refuses to share the presidency.\\nHun Sen and Ranariddh eventually form a coalition at summit convened by Sihanouk.\\nHun Sen remains prime minister, Ranariddh is president of the national assembly, and a new senate will be formed.\\nOpposition leader Rainsy left out.\\nHe seeks strong assurance of safety should he return to Cambodia.\\n\",\n",
        "                ]\n",
        "\n",
        "hypothesis_2 = \"China 's government said Thursday that two prominent dissidents arrested this week are suspected of endangering national security _ the clearest sign yet Chinese leaders plan to quash a would-be opposition party .\\nOne leader of a suppressed new political party will be tried on Dec. 17 on a charge of colluding with foreign enemies of China '' to incite the subversion of state power , '' according to court documents given to his wife on Monday .\\nWith attorneys locked up , harassed or plain scared , two prominent dissidents will defend themselves against charges of subversion Thursday in China 's highest-profile dissident trials in two years .\\n\"\n",
        "references_2 = \"Hurricane Mitch, category 5 hurricane, brought widespread death and destruction to Central American.\\nEspecially hard hit was Honduras where an estimated 6,076 people lost their lives.\\nThe hurricane, which lingered off the coast of Honduras for 3 days before moving off, flooded large areas, destroying crops and property.\\nThe U.S. and European Union were joined by Pope John Paul II in a call for money and workers to help the stricken area.\\nPresident Clinton sent Tipper Gore, wife of Vice President Gore to the area to deliver much needed supplies to the area, demonstrating U.S. commitment to the recovery of the region.\\n\"\n",
        "\n",
        "all_hypothesis = [hypothesis_1, hypothesis_2]\n",
        "all_references = [references_1, references_2]\n",
        "\n",
        "scores = evaluator.get_scores(all_hypothesis, all_references)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeTNzk10GSng"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwvyaaMbGOEw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9AqxO2GGOIG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBIBc4TBhVUc",
        "outputId": "922ae736-30a7-4a61-e566-8a8fc41db0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge-1': {'r': 0.34919517102615694, 'p': 0.4248799292214358, 'f': 0.38269036953218116}, 'rouge-2': {'r': 0.17655071776181952, 'p': 0.19880821541420524, 'f': 0.1858949298444496}, 'rouge-l': {'r': 0.3137683242311009, 'p': 0.3802641557128412, 'f': 0.3432646344228572}}\n"
          ]
        }
      ],
      "source": [
        "agg_rouge_score_1 = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score_1[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1yfOrnBhVUd",
        "outputId": "22651690-c0fe-4df4-cdeb-7e0d398fdc53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'precision': 0.7688697874546051, 'recall': 0.7728851437568665, 'f1': 0.7708407342433929}\n"
          ]
        }
      ],
      "source": [
        "agg_bertscore_1 = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for i in range(len(result_bertscore_list)):\n",
        "  for metric_type in ['precision','recall','f1']:\n",
        "    agg_bertscore_1[metric_type]+=((result_bertscore_list[i][metric_type][0])/len(result_bertscore_list))\n",
        "\n",
        "print(agg_bertscore_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVszpt4-nqrB"
      },
      "source": [
        "### Testing A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf6tWRR9nqrK"
      },
      "outputs": [],
      "source": [
        "def get_root_path():\n",
        "    '''\n",
        "    function to get root path of dataset\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    path = \"/content/drive/MyDrive/ExtractiveDataset/test-data\"  # use all 50 docs for testing if using abstractive dataset for training\n",
        "    return path\n",
        "\n",
        "def get_summary_data():\n",
        "    '''\n",
        "    function to get names, documents, and summaries\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "\n",
        "    path = get_root_path() + '/judgement'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_source = []\n",
        "    names = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            p = filename.rfind(\"/\")\n",
        "            names.append(filename[p+1:])\n",
        "            a = f.read()\n",
        "            data_source.append(a)\n",
        "    path = get_root_path() + '/summary/A2'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_summary = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            a = f.read()\n",
        "            l = len(a)\n",
        "            data_summary.append(a)\n",
        "\n",
        "    return names, data_source, data_summary\n",
        "\n",
        "def split_to_sentences(para):\n",
        "    sents = nltk.sent_tokenize(para)   # returns list of sentences from para\n",
        "    return sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uLe1vX-nqrL",
        "outputId": "f47ddcfc-243f-4530-cbd9-211cbd5981f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "names, data_source, data_summary = get_summary_data()\n",
        "print(len(names))\n",
        "print(len(data_source))\n",
        "print(len(data_summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8cR2f16nqrL",
        "outputId": "43795dae-262a-4c9a-b6c5-cd6422b482c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 2012_S_270.txt - 4248 : 1362 ,Value of p for doc 0 is 0.3206214689265537\n"
          ]
        }
      ],
      "source": [
        "# main loop to generate and save summaries of each document in the test dataset\n",
        "\n",
        "result_rouge_list = []\n",
        "result_bertscore_list = []\n",
        "\n",
        "for i in tqdm(range(len(data_source))):\n",
        "    name = names[i]\n",
        "    doc = data_source[i]\n",
        "    input_len = len(doc.split(\" \"))\n",
        "    req_len = get_req_len[name]\n",
        "    print(str(i) + \": \" + name +  \" - \" + str(input_len) + \" : \" + str(req_len), end = \" ,\")\n",
        "\n",
        "    nested = nest_sentences(doc,512)  # returns a list of chunks with word count < 512\n",
        "    p = float(req_len/input_len)  # p is the ratio of summary length to doc length\n",
        "    print('Value of p for doc {} is {}'.format(i,p))\n",
        "\n",
        "    extr_summ = generate_summary_gpu(nested,p)  # returns list of chunks summaries\n",
        "\n",
        "    extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    if len(extr_summ.split(\" \")) > req_len:\n",
        "        extr_summ = extr_summ.split(\" \")\n",
        "        extr_summ = extr_summ[:req_len]\n",
        "        extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    print(len(data_summary[i].split(' ')),len(extr_summ.split(' ')))\n",
        "\n",
        "    rouge = Rouge()\n",
        "    result_rouge_list.append(rouge.get_scores(extr_summ, data_summary[i], avg=True))\n",
        "    bertscore = load(\"bertscore\")\n",
        "    result_bertscore_list.append(bertscore.compute(predictions=[extr_summ], references=[data_summary[i]], model_type=\"distilbert-base-uncased\"))\n",
        "    print('---------------------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFp_pFhbnqrL",
        "outputId": "7e73bf4b-0a75-4f55-e81f-94c4c543f75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge-1': {'r': 0.21187794059777082, 'p': 0.49926828337230633, 'f': 0.2935809851176972}, 'rouge-2': {'r': 0.07604486106863347, 'p': 0.20917546307120924, 'f': 0.1102924148470025}, 'rouge-l': {'r': 0.20117182810722975, 'p': 0.47589578811019456, 'f': 0.2791278810436789}}\n"
          ]
        }
      ],
      "source": [
        "agg_rouge_score_2 = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score_2[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcW2GOVtnqrM",
        "outputId": "fc8c428b-4513-4f64-af77-8bb05f98c977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'precision': 0.7443345665931702, 'recall': 0.751188361644745, 'f1': 0.7473442792892456}\n"
          ]
        }
      ],
      "source": [
        "agg_bertscore_2 = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for i in range(len(result_bertscore_list)):\n",
        "  for metric_type in ['precision','recall','f1']:\n",
        "    agg_bertscore_2[metric_type]+=((result_bertscore_list[i][metric_type][0])/len(result_bertscore_list))\n",
        "\n",
        "print(agg_bertscore_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq3OehB2lG2p"
      },
      "source": [
        "###Average ROUGE score and BERTScores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNGu5vDBlG2p"
      },
      "outputs": [],
      "source": [
        "agg_rouge_score = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "  for j in ['r','p','f']:\n",
        "    agg_rouge_score[rouge_type][j]=(agg_rouge_score_1[rouge_type][j]+agg_rouge_score_2[rouge_type][j])*0.5\n",
        "\n",
        "print(agg_rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4xU56lElG2p"
      },
      "outputs": [],
      "source": [
        "print('ROUGE Scores of A1 Golden summary:')\n",
        "print(agg_rouge_score_1)\n",
        "print()\n",
        "print('ROUGE Scores of A2 Golden summary:')\n",
        "print(agg_rouge_score_2)\n",
        "print()\n",
        "print('ROUGE Average ROUGE scores of both summaries:')\n",
        "print(agg_rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wavoHLkQlSqj"
      },
      "outputs": [],
      "source": [
        "agg_bertscore = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for metric_type in ['precision','recall','f1']:\n",
        "  agg_bertscore[metric_type]+=(agg_bertscore_1[metric_type]+agg_bertscore_2[metric_type])*0.5\n",
        "\n",
        "print(agg_bertscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMT0j2GrlnQB"
      },
      "outputs": [],
      "source": [
        "print('BERTScores of A1 Golden summary:')\n",
        "print(agg_bertscore_1)\n",
        "print()\n",
        "print('BERTScores of A2 Golden summary:')\n",
        "print(agg_bertscore_2)\n",
        "print()\n",
        "print('Average BERTScores scores of both summaries:')\n",
        "print(agg_bertscore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YxI7Taks4dW"
      },
      "source": [
        "## Evaluation (Extractive) of Fine-Tuned BART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buCq6_2Ps4do"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate\n",
        "!pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl2L_Zhas4dp",
        "outputId": "58d130df-da87-49cc-b84b-aaf8c23f0198"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../')\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from rouge_score import rouge_scorer\n",
        "from rouge import Rouge\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from evaluate import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGakPhmQs4dp"
      },
      "outputs": [],
      "source": [
        "ext_analysis = pd.read_csv('Extractive Test Dataset Analysis.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x19yAOQUs4dq"
      },
      "outputs": [],
      "source": [
        "names, summ_word_count = list(ext_analysis['File']), list(ext_analysis['L = Average Summary Word Count'])\n",
        "\n",
        "get_req_len = {}\n",
        "for i in range(len(names)):\n",
        "  get_req_len[names[i]] = summ_word_count[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nuU0jIAs4dq",
        "outputId": "0d74f95b-f2eb-488e-97d4-b12161de3f5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'2012_S_270.txt': 1362,\n",
              " '2014_J_33.txt': 1007,\n",
              " '2014_R_41.txt': 1078,\n",
              " '2015_J_10.txt': 1126,\n",
              " '2015_S_368.txt': 1400}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_req_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdAdqUjqs4dr"
      },
      "outputs": [],
      "source": [
        "# Loading Model and tokenizer\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large', add_prefix_space=True)\n",
        "\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4oUEeXvHkn1",
        "outputId": "ad7012e0-ccc6-4bf4-a879-d5362d1c68ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(50272, 1024)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add special tokens if required\n",
        "\n",
        "new_tokens = ['<F>', '<RLC>', '<A>', '<S>', '<P>', '<R>', '<RPC>']\n",
        "\n",
        "special_tokens_dict = {'additional_special_tokens': new_tokens}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "bart_model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2WvkjOls4dr"
      },
      "outputs": [],
      "source": [
        "#bart_model = LitModel(learning_rate = 2e-5, tokenizer = tokenizer, model = model)\n",
        "\n",
        "bart_model = LitModel.load_from_checkpoint(\"output.ckpt\", learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9nrqb0Bs4ds"
      },
      "outputs": [],
      "source": [
        "def nest_sentences(document,chunk_length):\n",
        "    '''\n",
        "    function to chunk a document\n",
        "    input:  document           - Input document\n",
        "            chunk_length        - chunk length\n",
        "    output: list of chunks. Each chunk is a string.\n",
        "    '''\n",
        "    nested = []  # to store list of chunks of a doc\n",
        "    sent = []    # to store sentences per chunk in loop\n",
        "    length = 0\n",
        "    for sentence in nltk.sent_tokenize(document):\n",
        "        length += len(sentence.split(\" \"))       # adding no of words per sentence\n",
        "        if length < chunk_length:\n",
        "            sent.append(sentence)\n",
        "        else:\n",
        "            nested.append(\" \".join(sent))        # when word limit exceed chunk length (512 for t5) add the list of sentences (a chunk) after joining to the nested list\n",
        "            sent = []                            # create a new list to store next batch fof sentences for subsequent chunk\n",
        "            sent.append(sentence)\n",
        "            length = 0\n",
        "            length += len(sentence.split(\" \"))   # added to include length i=of sentence in else loop. Initially not added\n",
        "    if len(sent)>0:\n",
        "        nested.append(\" \".join(sent))            # including the final list of sentences to nested\n",
        "    return nested                                # return the list of chunks of that doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pniG_T-s4ds"
      },
      "outputs": [],
      "source": [
        "def generate_summary_gpu(nested_sentences,p=0.2):\n",
        "  '''\n",
        "    Function to generate summaries from the list containing chunks of the document\n",
        "    input:  nested_sentences - chunks\n",
        "            p - Number of words in summaries per word in the document\n",
        "    output: document summary\n",
        "    '''\n",
        "  summaries = []\n",
        "  for nested in nested_sentences:         # looping through each of the chunks\n",
        "    l = int(p * len(nested.split(\" \")))   # multiplying p with length of chunk to distribute summary length to that particular chunk\n",
        "    input_tokenized = tokenizer.encode(nested, truncation=True, return_tensors='pt')\n",
        "    summary_ids = bart_model.model.generate(input_tokenized,\n",
        "                                      length_penalty=0.01,\n",
        "                                      min_length=l-5,\n",
        "                                      max_length=l+5)\n",
        "    output = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
        "    summaries.append(output)\n",
        "  summaries = [sentence for sublist in summaries for sentence in sublist]\n",
        "  return summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chdb0vC3s4ds"
      },
      "source": [
        "### Testing A1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfZJ1XqCs4dt"
      },
      "outputs": [],
      "source": [
        "def get_root_path():\n",
        "    '''\n",
        "    function to get root path of dataset\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    path = \"/content/drive/MyDrive/ExtractiveDataset/test-data\"  # use all 50 docs for testing if using abstractive dataset for training\n",
        "    return path\n",
        "\n",
        "def get_summary_data():\n",
        "    '''\n",
        "    function to get names, documents, and summaries\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "\n",
        "    path = get_root_path() + '/judgement'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_source = []\n",
        "    names = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            p = filename.rfind(\"/\")\n",
        "            names.append(filename[p+1:])\n",
        "            a = f.read()\n",
        "            data_source.append(a)\n",
        "    path = get_root_path() + '/summary/A1'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_summary = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            a = f.read()\n",
        "            l = len(a)\n",
        "            data_summary.append(a)\n",
        "\n",
        "    return names, data_source, data_summary\n",
        "\n",
        "def split_to_sentences(para):\n",
        "    sents = nltk.sent_tokenize(para)   # returns list of sentences from para\n",
        "    return sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yLGXIwFs4dt"
      },
      "outputs": [],
      "source": [
        "names, data_source, data_summary = get_summary_data()\n",
        "print(len(names))\n",
        "print(len(data_source))\n",
        "print(len(data_summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "wPJEUyPQs4du",
        "outputId": "edce3bcf-53fe-43fb-8c9e-7b3c9e053658"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 2012_S_270.txt - 4248 : 1362 ,Value of p for doc 0 is 0.3206214689265537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:14<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-aee5d9350714>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Value of p for doc {} is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mextr_summ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# returns list of chunks summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mextr_summ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextr_summ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-a3d4b3cbfec0>\u001b[0m in \u001b[0;36mgenerate_summary_gpu\u001b[0;34m(nested_sentences, p)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# multiplying p with length of chunk to distribute summary length to that particular chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     summary_ids = bart_model.model.generate(input_tokenized,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                       \u001b[0mlength_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                       \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             )\n\u001b[1;32m   1610\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1612\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2907\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2909\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2910\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 )\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1380\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1262\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 )\n\u001b[1;32m   1118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1120\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# main loop to generate and save summaries of each document in the test dataset\n",
        "\n",
        "result_rouge_list = []\n",
        "result_bertscore_list = []\n",
        "\n",
        "for i in tqdm(range(2)):  # range(len(data_source))\n",
        "    name = names[i]\n",
        "    doc = data_source[i]\n",
        "    input_len = len(doc.split(\" \"))\n",
        "    req_len = get_req_len[name]\n",
        "    print(str(i) + \": \" + name +  \" - \" + str(input_len) + \" : \" + str(req_len), end = \" ,\")\n",
        "\n",
        "    nested = nest_sentences(doc,512)  # returns a list of chunks with word count < 512\n",
        "    p = float(req_len/input_len)  # p is the ratio of summary length to doc length\n",
        "    print('Value of p for doc {} is {}'.format(i,p))\n",
        "\n",
        "    extr_summ = generate_summary_gpu(nested,p)  # returns list of chunks summaries\n",
        "\n",
        "    extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    if len(extr_summ.split(\" \")) > req_len:\n",
        "        extr_summ = extr_summ.split(\" \")\n",
        "        extr_summ = extr_summ[:req_len]\n",
        "        extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    print(len(data_summary[i].split(' ')),len(extr_summ.split(' ')))\n",
        "\n",
        "    rouge = Rouge()\n",
        "    result_rouge_list.append(rouge.get_scores(extr_summ, data_summary[i], avg=True))\n",
        "    bertscore = load(\"bertscore\")\n",
        "    result_bertscore_list.append(bertscore.compute(predictions=[extr_summ], references=[data_summary[i]], model_type=\"distilbert-base-uncased\"))\n",
        "    print('---------------------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9acon-Uns4du"
      },
      "outputs": [],
      "source": [
        "agg_rouge_score_1 = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score_1[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7onZa0lXs4dv"
      },
      "outputs": [],
      "source": [
        "agg_bertscore_1 = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for i in range(len(result_bertscore_list)):\n",
        "  for metric_type in ['precision','recall','f1']:\n",
        "    agg_bertscore_1[metric_type]+=((result_bertscore_list[i][metric_type][0])/len(result_bertscore_list))\n",
        "\n",
        "print(agg_bertscore_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjW_P55Qs4dv"
      },
      "source": [
        "### Testing A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq1dWX7Vs4dv"
      },
      "outputs": [],
      "source": [
        "def get_root_path():\n",
        "    '''\n",
        "    function to get root path of dataset\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    path = \"/content/drive/MyDrive/ExtractiveDataset/test-data\"  # use all 50 docs for testing if using abstractive dataset for training\n",
        "    return path\n",
        "\n",
        "def get_summary_data():\n",
        "    '''\n",
        "    function to get names, documents, and summaries\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "\n",
        "    path = get_root_path() + '/judgement'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_source = []\n",
        "    names = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            p = filename.rfind(\"/\")\n",
        "            names.append(filename[p+1:])\n",
        "            a = f.read()\n",
        "            data_source.append(a)\n",
        "    path = get_root_path() + '/summary/A2'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_summary = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            a = f.read()\n",
        "            l = len(a)\n",
        "            data_summary.append(a)\n",
        "\n",
        "    return names, data_source, data_summary\n",
        "\n",
        "def split_to_sentences(para):\n",
        "    sents = nltk.sent_tokenize(para)   # returns list of sentences from para\n",
        "    return sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcW33bKHs4dw",
        "outputId": "f47ddcfc-243f-4530-cbd9-211cbd5981f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "names, data_source, data_summary = get_summary_data()\n",
        "print(len(names))\n",
        "print(len(data_source))\n",
        "print(len(data_summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO-iwvP_s4dw",
        "outputId": "43795dae-262a-4c9a-b6c5-cd6422b482c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 2012_S_270.txt - 4248 : 1362 ,Value of p for doc 0 is 0.3206214689265537\n"
          ]
        }
      ],
      "source": [
        "# main loop to generate and save summaries of each document in the test dataset\n",
        "\n",
        "result_rouge_list = []\n",
        "result_bertscore_list = []\n",
        "\n",
        "for i in tqdm(range(len(data_source))):\n",
        "    name = names[i]\n",
        "    doc = data_source[i]\n",
        "    input_len = len(doc.split(\" \"))\n",
        "    req_len = get_req_len[name]\n",
        "    print(str(i) + \": \" + name +  \" - \" + str(input_len) + \" : \" + str(req_len), end = \" ,\")\n",
        "\n",
        "    nested = nest_sentences(doc,512)  # returns a list of chunks with word count < 512\n",
        "    p = float(req_len/input_len)  # p is the ratio of summary length to doc length\n",
        "    print('Value of p for doc {} is {}'.format(i,p))\n",
        "\n",
        "    extr_summ = generate_summary_gpu(nested,p)  # returns list of chunks summaries\n",
        "\n",
        "    extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    if len(extr_summ.split(\" \")) > req_len:\n",
        "        extr_summ = extr_summ.split(\" \")\n",
        "        extr_summ = extr_summ[:req_len]\n",
        "        extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    print(len(data_summary[i].split(' ')),len(extr_summ.split(' ')))\n",
        "\n",
        "    rouge = Rouge()\n",
        "    result_rouge_list.append(rouge.get_scores(extr_summ, data_summary[i], avg=True))\n",
        "    bertscore = load(\"bertscore\")\n",
        "    result_bertscore_list.append(bertscore.compute(predictions=[extr_summ], references=[data_summary[i]], model_type=\"distilbert-base-uncased\"))\n",
        "    print('---------------------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6fip_9Us4dw",
        "outputId": "7e73bf4b-0a75-4f55-e81f-94c4c543f75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge-1': {'r': 0.21187794059777082, 'p': 0.49926828337230633, 'f': 0.2935809851176972}, 'rouge-2': {'r': 0.07604486106863347, 'p': 0.20917546307120924, 'f': 0.1102924148470025}, 'rouge-l': {'r': 0.20117182810722975, 'p': 0.47589578811019456, 'f': 0.2791278810436789}}\n"
          ]
        }
      ],
      "source": [
        "agg_rouge_score_2 = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score_2[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URv9Sx8ss4dx",
        "outputId": "fc8c428b-4513-4f64-af77-8bb05f98c977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'precision': 0.7443345665931702, 'recall': 0.751188361644745, 'f1': 0.7473442792892456}\n"
          ]
        }
      ],
      "source": [
        "agg_bertscore_2 = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for i in range(len(result_bertscore_list)):\n",
        "  for metric_type in ['precision','recall','f1']:\n",
        "    agg_bertscore_2[metric_type]+=((result_bertscore_list[i][metric_type][0])/len(result_bertscore_list))\n",
        "\n",
        "print(agg_bertscore_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QClB6qAos4dx"
      },
      "source": [
        "###Average ROUGE score and BERTScores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWO8diP5s4dx"
      },
      "outputs": [],
      "source": [
        "agg_rouge_score = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "  for j in ['r','p','f']:\n",
        "    agg_rouge_score[rouge_type][j]=(agg_rouge_score_1[rouge_type][j]+agg_rouge_score_2[rouge_type][j])*0.5\n",
        "\n",
        "print(agg_rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcwpEPAls4dy"
      },
      "outputs": [],
      "source": [
        "print('ROUGE Scores of A1 Golden summary:')\n",
        "print(agg_rouge_score_1)\n",
        "print()\n",
        "print('ROUGE Scores of A2 Golden summary:')\n",
        "print(agg_rouge_score_2)\n",
        "print()\n",
        "print('ROUGE Average ROUGE scores of both summaries:')\n",
        "print(agg_rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT-0-ZIJs4dy"
      },
      "outputs": [],
      "source": [
        "agg_bertscore = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for metric_type in ['precision','recall','f1']:\n",
        "  agg_bertscore[metric_type]+=(agg_bertscore_1[metric_type]+agg_bertscore_2[metric_type])*0.5\n",
        "\n",
        "print(agg_bertscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLUFv8Q1s4dy"
      },
      "outputs": [],
      "source": [
        "print('BERTScores of A1 Golden summary:')\n",
        "print(agg_bertscore_1)\n",
        "print()\n",
        "print('BERTScores of A2 Golden summary:')\n",
        "print(agg_bertscore_2)\n",
        "print()\n",
        "print('Average BERTScores scores of both summaries:')\n",
        "print(agg_bertscore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGRtJXxdvnrl"
      },
      "source": [
        "## Pegasus-X Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmOX7d1evnrm",
        "outputId": "50b2b9ea-856c-44c7-8215-9fee034447d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/722.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/722.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.4/722.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/729.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m729.2/729.2 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# This run uses Pytorch Lightening to finetune the model\n",
        "!pip install -q pytorch-lightning\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZoBlmgwvnro"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from nltk import tokenize\n",
        "import nltk\n",
        "import transformers\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "#Source - https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1\n",
        "class LitModel(pl.LightningModule):\n",
        "  # Instantiate the model\n",
        "  def __init__(self, learning_rate, tokenizer, model):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.model = model\n",
        "    self.learning_rate = learning_rate\n",
        "    # self.freeze_encoder = freeze_encoder\n",
        "    # self.freeze_embeds_ = freeze_embeds\n",
        "#     self.hparams = argparse.Namespace()\n",
        "\n",
        "    self.hparams.freeze_encoder = True\n",
        "    self.hparams.freeze_embeds = True\n",
        "    self.hparams.eval_beams = 4\n",
        "    # self.hparams = hparams\n",
        "\n",
        "    if self.hparams.freeze_encoder:\n",
        "      freeze_params(self.model.get_encoder())\n",
        "\n",
        "    if self.hparams.freeze_embeds:\n",
        "      self.freeze_embeds()\n",
        "\n",
        "  def freeze_embeds(self):\n",
        "    ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n",
        "    freeze_params(self.model.model.shared)\n",
        "    for d in [self.model.model.encoder, self.model.model.decoder]:\n",
        "      freeze_params(d.embed_positions)\n",
        "      freeze_params(d.embed_tokens)\n",
        "\n",
        "  # Do a forward pass through the model\n",
        "  def forward(self, input_ids, **kwargs):\n",
        "    return self.model(input_ids, **kwargs)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    # Load the data into variables\n",
        "    src_ids, src_mask = batch[0], batch[1]\n",
        "    tgt_ids = batch[2]\n",
        "    # Shift the decoder tokens right (but NOT the tgt_ids)\n",
        "    decoder_input_ids = shift_tokens_right(tgt_ids, self.tokenizer.pad_token_id)\n",
        "\n",
        "    # Run the model and get the logits\n",
        "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "    lm_logits = outputs[0]\n",
        "    # Create the loss function\n",
        "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "    # Calculate the loss on the un-shifted tokens\n",
        "    loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "    return {'loss':loss}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "\n",
        "    src_ids, src_mask = batch[0], batch[1]\n",
        "    tgt_ids = batch[2]\n",
        "\n",
        "    decoder_input_ids = shift_tokens_right(tgt_ids, self.tokenizer.pad_token_id)\n",
        "\n",
        "    # Run the model and get the logits\n",
        "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "    lm_logits = outputs[0]\n",
        "\n",
        "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "    val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "    return {'loss': val_loss}\n",
        "\n",
        "  # Method that generates text using the BartForConditionalGeneration's generate() method\n",
        "  def generate_text(self, text, eval_beams, early_stopping = True, max_len = 1024):\n",
        "    ''' Function to generate text '''\n",
        "    generated_ids = self.model.generate(\n",
        "        text[\"input_ids\"],\n",
        "        attention_mask=text[\"attention_mask\"],\n",
        "        use_cache=True,\n",
        "        decoder_start_token_id = self.tokenizer.pad_token_id,\n",
        "        num_beams= eval_beams,\n",
        "        max_length = max_len,\n",
        "        early_stopping = early_stopping\n",
        "    )\n",
        "    return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n",
        "\n",
        "def freeze_params(model):\n",
        "  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n",
        "      adapted from finetune.py '''\n",
        "  for layer in model.parameters():\n",
        "    layer.requires_grade = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvUEuwxHvnro"
      },
      "outputs": [],
      "source": [
        "# Create a dataloading module as per the PyTorch Lightning Docs\n",
        "class SummaryDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, tokenizer, df, batch_size):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.data = df\n",
        "\n",
        "  # Loads and splits the data into training, validation and test sets with a 60/20/20 split\n",
        "  def prepare_data(self):\n",
        "    self.train, self.validate, self.test = np.split(self.data.sample(frac=1), [int(.6*len(self.data)), int(.8*len(self.data))])\n",
        "\n",
        "  # encode the sentences using the tokenizer\n",
        "  def setup(self, stage):\n",
        "    self.train = encode_sentences(self.tokenizer, self.train['source'], self.train['target'])\n",
        "    self.validate = encode_sentences(self.tokenizer, self.validate['source'], self.validate['target'])\n",
        "    self.test = encode_sentences(self.tokenizer, self.test['source'], self.test['target'])\n",
        "\n",
        "  # Load the training, validation and test sets in Pytorch Dataset objects\n",
        "  def train_dataloader(self):\n",
        "    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])\n",
        "    train_data = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n",
        "    return train_data\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels'])\n",
        "    val_data = DataLoader(dataset, batch_size = self.batch_size)\n",
        "    return val_data\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels'])\n",
        "    test_data = DataLoader(dataset, batch_size = self.batch_size)\n",
        "    return test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-trt-BOlvnrp"
      },
      "outputs": [],
      "source": [
        "def shift_tokens_right(input_ids, pad_token_id):\n",
        "  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n",
        "      This is taken directly from modeling_bart.py\n",
        "  \"\"\"\n",
        "  prev_output_tokens = input_ids.clone()\n",
        "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
        "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
        "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
        "  return prev_output_tokens\n",
        "\n",
        "def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=1024, min_length = 512, pad_to_max_length=True, return_tensors=\"pt\"):\n",
        "  ''' Function that tokenizes a sentence\n",
        "      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n",
        "      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n",
        "  '''\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  target_ids = []\n",
        "  tokenized_sentences = {}\n",
        "\n",
        "  for sentence in source_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=max_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim = 0)\n",
        "  attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "\n",
        "  for sentence in target_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=min_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "    # Shift the target ids to the right\n",
        "    # shifted_target_ids = shift_tokens_right(encoded_dict['input_ids'], tokenizer.pad_token_id)\n",
        "    target_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  target_ids = torch.cat(target_ids, dim = 0)\n",
        "\n",
        "\n",
        "  batch = {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "      \"labels\": target_ids,\n",
        "  }\n",
        "\n",
        "  return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwNFIAb6vphp"
      },
      "source": [
        "## Fine-Tuning Pegasus-X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsWXWt4Jvphp"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/mcs.xlsx\"\n",
        "df = pd.read_excel(filepath,usecols='B,C')\n",
        "#df = pd.read_excel(filename,index_col=0)\n",
        "df.rename(columns = {'data':'source', 'summary':'target'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "EvTcLzPAvphq",
        "outputId": "e17fc7b2-1cf2-44c7-eae0-754fe940004e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-e58e6983-7045-49bd-adc5-a8a2188269fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Appeal No. LXVI of 1949. Appeal from the High ...</td>\n",
              "      <td>The charge created in respect of municipal pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dudhuria vs Commissioner of Income tax, Calcut...</td>\n",
              "      <td>The charge in respect of urban immoveable prop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kania J., as he then was, said as follows : \"I...</td>\n",
              "      <td>The expression \"capital charge\" in s.9(1) (iv)...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e58e6983-7045-49bd-adc5-a8a2188269fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e52ac128-9513-4b26-8f2c-5e5a0acfe6f0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e52ac128-9513-4b26-8f2c-5e5a0acfe6f0')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e52ac128-9513-4b26-8f2c-5e5a0acfe6f0 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e58e6983-7045-49bd-adc5-a8a2188269fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e58e6983-7045-49bd-adc5-a8a2188269fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              source  \\\n",
              "0  Appeal No. LXVI of 1949. Appeal from the High ...   \n",
              "1  Dudhuria vs Commissioner of Income tax, Calcut...   \n",
              "2  Kania J., as he then was, said as follows : \"I...   \n",
              "\n",
              "                                              target  \n",
              "0  The charge created in respect of municipal pro...  \n",
              "1  The charge in respect of urban immoveable prop...  \n",
              "2  The expression \"capital charge\" in s.9(1) (iv)...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "343bf943bedf498bb9f6e252c10eab6c",
            "658f6b1eeb3d4f40b9e9ef8281d24918",
            "ed2b35ef568b421486fb0c5fdff588cf",
            "957685d3befc48af85f7d159a701afa3",
            "9998d239f89445d0941ea73d883601f7",
            "2c216fde7be0494592363138d76eeb74",
            "e2316d64cf0e4b30aaa0f1badfd65a9d",
            "0f03962741d5463a9dd42dbd51d5fba8",
            "390d0f9dc0284726ac9ee3bebb5904d1",
            "cc9dd6d2dd6948dcbf8c9823bcbe8b8d",
            "775ec9c39b1644c591c3e0a2e5569fec",
            "b5f63014d64c4e2cad87bf54742b85c2",
            "48e91a57a23242039a6d9065b95cc0cc",
            "0c87889469fd436696be18ec99057847",
            "969d2b10603a4c75b90a6711c22bd6a6",
            "43fd64aefdea498f9e426a42b5ed7f86",
            "cb3aa40c57814ea6aae1463fafec5da7",
            "12520932ac784f13aec2bc5452370880",
            "33caefba554649e5ad6970d14385a690",
            "a85bad7ce0584070b4365e3bd60c65bb",
            "9d733fdba81742e298d13e2f0d8fba6e",
            "f4b40914eb044fb69c669b7d578d97e2",
            "e7f0810f826648c2833d107811c7b89d",
            "f3d16a5f58e84374a8a7440b754035be",
            "cadddd3f7fe04f3984c5e4cc771ec9c7",
            "96549dd0c7574a25a28409b08bd57b5b",
            "d6c045ef29eb45bcbc4355e512b986af",
            "683bf52e2f614a0aa5ba4b7eca356c47",
            "985960bcd1074f90a3c880f7bd3d077b",
            "fd64d8fadf5e41b2a1d5aeaa3c258f40",
            "e0f9751927f24605b94cd4d14b95cfea",
            "e7f859b76a8e43748e1d604ced91f09e",
            "d06e3bd592774bc68a8936ede7621cd1",
            "4ede9efd653148759649c3c6b50ef0c4",
            "0bf4795eef79446c996ea0a7cbf12fef",
            "d5cea8e955c2440f928e464008069bbf",
            "6cb190e2fef541ef817e185b674edb58",
            "1ceaddc142b44ae0be729c791361c63b",
            "a6c57d803d2f473db134997f01269445",
            "cc29d7bc0e42486e92836567a865a9b7",
            "73f1b7b3fa2a4d62921f203a780f9c88",
            "6825ff6cf0854906b3ee6a3f3a6afdec",
            "62b113271b5842a0b5c5a02d8cc66622",
            "9a2f344f94b342a5b87385c840419c5b",
            "fdc7db217c654a07a59594eb7d29c9b0",
            "5cacdf31d03d457db7d0235eb5a8c70b",
            "ce3d7e7c597c44209a10da8e10e643d3",
            "000b810d3dad49a497bdd6916a5db059",
            "a5c4912ba0e64a6ebb536a2a9230674f",
            "ce316b9263a143f8ab64e79ece81de26",
            "dbb74dd0d23c42668e9f20ba60586134",
            "e15b069413c442b7975c09e9cfe97392",
            "cd373f434ab7464fbafb9381aa7f1da4",
            "06421b7e4d49473cb23cbd783a9a41b4",
            "3d4e66587fc34a1399401c8a0ebe9521"
          ]
        },
        "id": "JRliM_tjvphq",
        "outputId": "e086ffd9-c662-4153-b8a3-6ca0be38df65"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "343bf943bedf498bb9f6e252c10eab6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5f63014d64c4e2cad87bf54742b85c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f0810f826648c2833d107811c7b89d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ede9efd653148759649c3c6b50ef0c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdc7db217c654a07a59594eb7d29c9b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loading Model and tokenizer\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large', add_prefix_space=True)\n",
        "\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZjK2mTbvphr",
        "outputId": "fdeed767-a004-477a-8549-9c3b19c20662"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(50272, 1024)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add special tokens if required\n",
        "\n",
        "new_tokens = ['<F>', '<RLC>', '<A>', '<S>', '<P>', '<R>', '<RPC>']\n",
        "\n",
        "special_tokens_dict = {'additional_special_tokens': new_tokens}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "bart_model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhn0OfPHvphr"
      },
      "outputs": [],
      "source": [
        "summary_data = SummaryDataModule(tokenizer, df, batch_size = 1)\n",
        "model = LitModel(learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ocdymsuvphr"
      },
      "outputs": [],
      "source": [
        "# put in chatgpt for code implementation - \"finetuning BART model with LitModel multi GPU implementation with tensorflow\"\n",
        "# for early stopping - \"finetuning BART model with LitModel and adding a early stopping criterea with lightning module\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a3dyqDwvphr",
        "outputId": "9cac34c1-9521-4a63-da62-95787767ea11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "# import pytorch_lightning as pl\n",
        "\n",
        "trainer = pl.Trainer(accelerator=\"auto\", # \"accelarator='auto'\" keyword which automatically uses all available GPUs\n",
        "                     max_epochs = 3,\n",
        "                     min_epochs = 2,\n",
        "                     precision = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "701c2582aec1435ea0d8d7b917dfefeb",
            "7248a75b3b28464cb3d337282670bd21",
            "9d2102b370e44e1a952de2c02fd878ef",
            "9622f0a288794e86823d7767b80f0306",
            "ffd323f93ca4416b9fe962faf3e8640c",
            "36837c1a41694878b3b0b6233aad4250",
            "5fa26c1f786a48a7a2aa9f9785caadf1",
            "7133d67addc4490dbed7629c29e7f51f",
            "cda793a53446445ea39cf84c861475c9",
            "8202feb9574949cda81385567d1a0732",
            "7f18fc2aee19427a8e6e73c70a23427b",
            "19e6a261c3c841bd98c51285c586d7f1",
            "1be19a08e990434aa0a4d8aa4bb636c8",
            "4fdce4b2e1e0447abafe75b5b7b3ae9d",
            "039f90b899ca47c7a72b44c05aa3d231",
            "e2280b37404748ac8ee987f752169a5b",
            "b84d53ebde12442da0dfd6d855c08e32",
            "d7270698670c4186ab804d5a35d2d37c",
            "319744f931c9494094e061995c2bf646",
            "a250b9f9b4a648f7b75c8730e0d45027",
            "6b0bf06a805f4828a024f3869b7711a7",
            "5164f226cc4d43fdb89ae5d529a43712",
            "1e21df12620b4339a3d415d9104c3254",
            "40716c63ca234059bbb8f0fb56cc4e1d",
            "05c9bbf29ed8423193e3266b870825ac",
            "0b19d78b971b4980bf2cea71f668e908",
            "ec820f74db204d41854f190d024d43d8",
            "019b2a2008e8431da355e7374b7a1c66",
            "d093f1d7d3544bc0b359195ed090f4f4",
            "dee9a1214315453eb0457b89362582ee",
            "0e85567675a74fcdaaf59bdc51f63b18",
            "f748bbb050494f68a00d3681c9594c0b",
            "a167fe71d31249169743e4f2f90e225b",
            "545072ee19ca498d883dba244a8ff96c",
            "b0dc6ab7b86d4c179cd815d288803c7d",
            "9a2747a5d5934d14a962f216fbd6574c",
            "f034c1ffe4f6463b8ba1df6321a9feef",
            "8f5624fe417740c5b399b493e993c46a",
            "1d633d5c31164331a252b7d6c4eefd0e",
            "0955b13fe49145de8440afad6d6c448c",
            "0d2c89406deb426596d6b79ed13f34fd",
            "a052678115c14bad88389d02264673d7",
            "3adc7241b621413f884aeaffac53385c",
            "358facabc8744a668fd1ac57a6d98653",
            "ba31edf28a624daa933aa05ec239cdcc",
            "31ebd380e9244b2e87715d1a8e6fb2b4",
            "4a842a2468ca402fb82bd3f63853c261",
            "40625ba561334f1d8cea34b98683a0c0",
            "c5781e6a87f848689679e41b2e1f7600",
            "b1d28e620505477ebf607e590aff5b61",
            "04631b1105974b6fb5005278c6458f59",
            "4397ca8104d141409052dacd05d59817",
            "6745552a8cbc432c8af7f4daf9081af7",
            "2b9e6c69b36c4e2180be94fcc663f9e9",
            "844b32fc38394caeae3340ad83f3f24a"
          ]
        },
        "id": "owUArt1Bvphs",
        "outputId": "c0f70e82-bdab-4f63-fbe9-482c818080c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                         | Params\n",
            "-------------------------------------------------------\n",
            "0 | model | BartForConditionalGeneration | 406 M \n",
            "-------------------------------------------------------\n",
            "406 M     Trainable params\n",
            "0         Non-trainable params\n",
            "406 M     Total params\n",
            "1,625.194 Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "701c2582aec1435ea0d8d7b917dfefeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e6a261c3c841bd98c51285c586d7f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e21df12620b4339a3d415d9104c3254",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "545072ee19ca498d883dba244a8ff96c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba31edf28a624daa933aa05ec239cdcc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, summary_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRfy2Vd2vphs"
      },
      "outputs": [],
      "source": [
        "#Save the model\n",
        "trainer.save_checkpoint(\"output.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjfYTmx_zuv7"
      },
      "source": [
        "## Evaluation (Extractive) of Pre-Trained Pegasus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iywTwy99zuv9"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate\n",
        "!pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QPYvQ-szuv9",
        "outputId": "b82ef8bf-d837-4cb3-a931-a930a9aad564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../')\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from rouge_score import rouge_scorer\n",
        "from rouge import Rouge\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from evaluate import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LKJQlrHzuv-"
      },
      "outputs": [],
      "source": [
        "ext_analysis = pd.read_csv('Extractive Test Dataset Analysis.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oursq_udzuv_"
      },
      "outputs": [],
      "source": [
        "names, summ_word_count = list(ext_analysis['File']), list(ext_analysis['L = Average Summary Word Count'])\n",
        "\n",
        "get_req_len = {}\n",
        "for i in range(len(names)):\n",
        "  get_req_len[names[i]] = summ_word_count[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjC_DPcazuv_",
        "outputId": "17877991-6e37-4773-8b4e-7e21b71720ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2012_S_270.txt': 1362,\n",
              " '2014_J_33.txt': 1007,\n",
              " '2014_R_41.txt': 1078,\n",
              " '2015_J_10.txt': 1126,\n",
              " '2015_S_368.txt': 1400}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "get_req_len"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "model_name = 'google/pegasus-x-base'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "sBCiNRl9utvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    input_ids = tokenizer.encode(text, truncation=True, return_tensors='pt')\n",
        "    return input_ids\n",
        "\n",
        "# Example usage\n",
        "text = \"\"\"Virat Kohli (Hindi pronunciation: [ʋɪˈɾɑːʈ ˈkoːɦli] (listen); born 5 November 1988) is an Indian international cricketer and the former captain of the Indian national cricket team who plays as a right-handed batsman for Royal Challengers Bangalore in the IPL and for Delhi in Indian domestic cricket. Widely regarded as one of the greatest batsmen of all time,[4] Kohli holds the records for scoring most runs in T20 internationals and in the IPL. In 2020, the International Cricket Council named him the male cricketer of the decade. Kohli has also contributed to India's successes, including winning the 2011 World Cup and the 2013 Champions trophy.\n",
        "\n",
        "Born and raised in New Delhi, Kohli trained at the West Delhi Cricket Academy and started his youth career with the Delhi Under-15 team. He made his international debut in 2008 and quickly became a key player in the ODI team and later made his Test debut in 2011. In 2013, Kohli reached the number one spot in the ICC rankings for ODI batsmen for the first time. During 2014 T20 World Cup, he set a record for the most runs scored in the tournament. In 2018, he achieved yet another milestone, becoming the world's top-ranked Test batsman, making him the only Indian cricketer to hold the number one spot in all three formats of the game. His form continued in 2019, when he became the first player to score 20,000 international runs in a single decade. In 2021, Kohli made the decision to step down as the captain of the Indian national team for T20Is, following the T20 World Cup and in early 2022 he stepped down as the captain of the Test team as well.\n",
        "\n",
        "He has received many accolades for his performances on the cricket field. He was recognized as the ICC ODI Player of the Year in 2012 and has won the Sir Garfield Sobers Trophy, given to the ICC Cricketer of the Year, on two occasions, in 2017 and 2018 respectively. Subsequently, Kohli also won ICC Test Player of the Year and ICC ODI Player of the Year awards in 2018, becoming the first player to win both awards in the same year. Additionally, he was named the Wisden Leading Cricketer in the World for three consecutive years, from 2016 to 2018. At the national level, Kohli was honoured with the Arjuna Award in 2013, the Padma Shri under the sports category in 2017 and the Khel Ratna award, India's highest sporting honour, in 2018.\"\"\"\n",
        "input_ids = preprocess(text)\n",
        "print(len(text.split(' ')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XITU_Az8utya",
        "outputId": "cc8bb692-07c6-4393-bd6c-0ae0f000c292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.generate(input_ids, num_beams=1, early_stopping=True)\n",
        "\n",
        "summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(f\"Summary: {summary}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zNh3Jxgut2A",
        "outputId": "8247b75e-bb30-4453-fd23-674b354fd8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (16384) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: ,,, each a...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"\"'Some people belive that the so called \"face\" on mars was created by life on mars. This is not the case. The face on Mars is a naturally occuring land form called a mesa. It was not created by aliens, and there is no consiracy to hide alien lifeforms on mars. There is no evidence that NASA has found that even suggests that this face was created by aliens.\\n\\nA mesa is a naturally occuring rock formation, that is found on Mars and Earth. This \"face\" on mars only looks like a face because humans tend to see faces wherever we look, humans are obviously extremely social, which is why our brain is designed to recognize faces.\\n\\nMany conspiracy theorists believe that NASA is hiding life on Mars from the rest of the world. These people would be very wrong. If NASA found life on Mars, then they would get millions of people\\'s attention. NASA\\'s budget would increase drasticly, which means that their workers would get paid more. There is no good reason that NASA would hide life on Mars from the rest of the world.\\n\\nSo, NASA is not hiding life on Mars from us, and they are not trying to trick us into thinking that the \"face\" on mars is just a mesa, because it actually is. NASA hiding life would be illogical, because if they found life on Mars, they would make a lot of money, and we all know that the people at NASA aren\\'t illogical people.'\"\""
      ],
      "metadata": {
        "id": "OtaKNDzkxsQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, PegasusXForConditionalGeneration\n",
        "\n",
        "model = PegasusXForConditionalGeneration.from_pretrained(\"google/pegasus-x-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-x-base\")\n",
        "\n",
        "ARTICLE_TO_SUMMARIZE = (\n",
        "    \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
        "    \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
        "    \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
        ")\n",
        "inputs = tokenizer(ARTICLE_TO_SUMMARIZE, max_length=1024, return_tensors=\"pt\")  # `max_new_tokens` to control the maximum length of the generation.\n",
        "\n",
        "# Generate Summary\n",
        "summary_ids = model.generate(inputs[\"input_ids\"])\n",
        "tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "ARYT2Eq8ut3z",
        "outputId": "411787fb-f853-4da5-fef3-b4ede605569b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (16384) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-10d60f2c5a89>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Generate Summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msummary_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             )\n\u001b[1;32m   1610\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1612\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2980\u001b[0m             )\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reorder_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_key_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_in_generate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus_x/modeling_pegasus_x.py\u001b[0m in \u001b[0;36m_reorder_cache\u001b[0;34m(past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0;31m# cached cross_attention states don't have to be reordered -> they are always the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m             reordered_past += (\n\u001b[0;32m-> 1696\u001b[0;31m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpast_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1697\u001b[0m             )\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreordered_past\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus_x/modeling_pegasus_x.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0;31m# cached cross_attention states don't have to be reordered -> they are always the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m             reordered_past += (\n\u001b[0;32m-> 1696\u001b[0;31m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpast_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1697\u001b[0m             )\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreordered_past\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urnv2HeJy6pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b42675dc45254a1ea754c73b5baa3bfb",
            "18dccbc2d8d8436884adcbd2e48710aa",
            "b9e86985ba554a978d03e0319827dfaf",
            "f799ed8f0f75465697e23f2382458d9a",
            "cc6ee55f7db7488eb651be4a03f14376",
            "aac607e248ac44dd880e6c6af4129eee",
            "c7b3df5601044215b18950f2a4b69b00",
            "2845e9abda8d4b82a7095049d04e5b83",
            "12a256b02a234ccaac1fda36ff120f90",
            "00d7daa906934af78a03d3c2f267a531",
            "deb92ad15c4c403e823118c6e3571bea",
            "28fe7739ee6c40629dcc46b7c0a566db",
            "922762114c3b4919bd0d9f4589bf8560",
            "f76cf01f6a974e21ad3fbc0def764609",
            "49baa69beb5745ecb36ab37f4caf2c41",
            "5b89412edc9f456cb11cf5ec03d9fc92",
            "690d77dfc6054fe597541addec540e61",
            "43eeb3a43f5c4cee8598ba177653e388",
            "d7a281975ec74980bcb5c8a4e2ca0f20",
            "6b2b0a6872c04132844f481bbf7b9562",
            "c26c466e871d4f89be32427449ce91bc",
            "5bd7f71a30f34332832d0681d62595db",
            "7eea1d8962c94ead9d817da6212374fe",
            "529bfa606f2d4a96ac274173011a5516",
            "19dc2b9cf8f64ec5a2265bc8eb1bcaad",
            "02fa1b0898eb45709ee27f0278d4f32f",
            "e4a387ad22094d2f9eaf1e9372699e58",
            "628bc170cee8485d944f3dffae0ab0a4",
            "757c9065de5a4da8aa6d7b1effa2d8c2",
            "0569025b87584f3baa164433f54fc213",
            "b28477acd34b441eb80bbcb8feb3c0ca",
            "82e4b52e88b44bebbb0a6280612f189b",
            "dbc7b5e995b0474aa5d1536f3808d865",
            "86eeefd5211c474d82482da13cf75854",
            "b19f0b7b0efd4f60aba2558c42452268",
            "fd9679d97095437d9a5c68fa696cc000",
            "47c9e4ecec3345f5a1055fe58345fdf0",
            "5de18f5e700e4905a4a024d4e0acc06f",
            "18e2fee7561f4ad7983fefaf53ea6848",
            "d6bad2eb6402469abf58a65dd32ad397",
            "1ab14a8461954111b095d85f76f4b6b5",
            "3731eaa44eb64f2b9a0e0acda7406c4a",
            "95fa349725354d5284ffe4ad9b474c95",
            "53080f809c5e4d048ff7f4593cf8b66c"
          ]
        },
        "id": "vEjiniHZz_Bd",
        "outputId": "d0b12d6b-2969-4e04-8256-e3f7aec21c5f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b42675dc45254a1ea754c73b5baa3bfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28fe7739ee6c40629dcc46b7c0a566db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7eea1d8962c94ead9d817da6212374fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/6.60M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86eeefd5211c474d82482da13cf75854",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"google/pegasus-x-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "encoder_max_length = 1024*16\n",
        "decoder_max_length = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "d2fd1e17e32a46739bd9192f26084c2c",
            "eaa525034a1d45979f4aca4017ae25dd",
            "c2ef15bf4f85440bb6279c8ad82b9079",
            "c825b72521534d1e99c88ef88aed53e1",
            "d3e554a1bb7a4a22bd77fc055aa7587c",
            "fb565d2920134f82af21837a6578d473",
            "5d0119f4365340ffba67f216640048d7",
            "0405e02d9a6a45e8aa4c205f8d5dbc82",
            "d9d34047162a49fea38b229c4eb16f8c",
            "5e6707ee340a48bdbd10819d2254084d",
            "940d0566d80748cc800cd4cea51402a8",
            "d3d805b24ef840798f9807d1a8055d1a",
            "49fb00072185411e85df878c40c8cf8e",
            "4d53aa2de03d4812a5eb1fc473e6a60c",
            "70194ae49b374f0996cde1005204fcde",
            "744ac6ee7b344d9e8e411ea7c9e21244",
            "90d140eca1064fb0b8eaec92df9e4b89",
            "ee89d969984c4be2887745a7bd0a105d",
            "9d18c4bf97964275ace29ba6a5a38bf6",
            "d8498a075b2142eca7886db9ebff2e6a",
            "abade9d7576249ed90f502c079eb19e6",
            "678fe89ab1ea4d25bf8f1f74d41e714f",
            "b8af7e2cd8cf4c398718bf0c0db926c3",
            "cc87999a860c495fa2ec583bd8d76fae",
            "8e7dc265cd6d4ccf90f19bbdc870a80d",
            "332dbb89aea04ca2ab78e6bbf0c98a48",
            "c862903d51de4c0ebfaf162d43ae5d63",
            "a784f6e9da5145dd88e194841b0cc091",
            "cdc7c95db9ce41dc8385c6bfaa645dc1",
            "b0aeadfd5ac848728660ed3ddd162253",
            "f79d5409fb924d41a72db28e2f677e8b",
            "cc1abee02d7044e6a7cf9b159750cfb4",
            "4bd030bf0c494ac0aa686adcd1e4f924"
          ]
        },
        "id": "8rLWsMD20G-G",
        "outputId": "51283850-c82f-4f17-e184-11e3600e4908"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2fd1e17e32a46739bd9192f26084c2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3d805b24ef840798f9807d1a8055d1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8af7e2cd8cf4c398718bf0c0db926c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/262 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "led = AutoModelForSeq2SeqLM.from_pretrained(model_name, gradient_checkpointing=True, use_cache=False)\n",
        "# set generate hyperparameters\n",
        "led.config.num_beams = 2\n",
        "led.config.max_length = decoder_max_length\n",
        "led.config.min_length = 256\n",
        "led.config.early_stopping = True\n",
        "led.config.no_repeat_ngram_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0xlb_l30HBt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "led.eval()\n",
        "\n",
        "def generate_summary_gpu(input_text, l):\n",
        "\tinputs = tokenizer(\n",
        "\t\tinput_text,\n",
        "\t\tpadding=\"max_length\",\n",
        "\t\ttruncation=True,\n",
        "\t\tmax_length=encoder_max_length,\n",
        "\t\treturn_tensors=\"pt\",\n",
        "\t)\n",
        "\tinput_ids = inputs['input_ids']\n",
        "\tattention_mask = inputs['attention_mask']\n",
        "\tglobal_attention_mask = torch.zeros_like(attention_mask)\n",
        "\t# put global attention on <s> token\n",
        "\tglobal_attention_mask[:, 0] = 1\n",
        "\tl = max(l,256)\n",
        "\tl = min(l,1024)\n",
        "\toutputs = led.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask, max_length = l, num_beams = 2,repetition_penalty = 2.5,early_stopping = True)\n",
        "\tpreds = [tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_space=True) for gen_id in outputs]\n",
        "\treturn \"\".join(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VysMtqUa1ZTZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "led.eval()\n",
        "\n",
        "def generate_summary_gpu(input_text, l):\n",
        "  summaries = []\n",
        "  input_tokenized = tokenizer.encode(input_text, truncation=True, return_tensors='pt')\n",
        "  summary_ids = led.generate(input_tokenized,\n",
        "                                      length_penalty=0.01,\n",
        "                                      min_length=l-5,\n",
        "                                      max_length=l+5)\n",
        "  output = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
        "  summaries.append(output)\n",
        "  summaries = [sentence for sublist in summaries for sentence in sublist]\n",
        "  return summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebj4oavnzuwB"
      },
      "source": [
        "### Testing A1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFis0qBiz4O2",
        "outputId": "5ef0c479-584f-4c9a-8d3e-5ea339904c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIECb4ACzuwB"
      },
      "outputs": [],
      "source": [
        "def get_root_path():\n",
        "    '''\n",
        "    function to get root path of dataset\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    path = \"/content/drive/MyDrive/ExtractiveDataset/test-data\"  # use all 50 docs for testing if using abstractive dataset for training\n",
        "    return path\n",
        "\n",
        "def get_summary_data():\n",
        "    '''\n",
        "    function to get names, documents, and summaries\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "\n",
        "    path = get_root_path() + '/judgement'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_source = []\n",
        "    names = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            p = filename.rfind(\"/\")\n",
        "            names.append(filename[p+1:])\n",
        "            a = f.read()\n",
        "            data_source.append(a)\n",
        "    path = get_root_path() + '/summary/A1'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_summary = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            a = f.read()\n",
        "            l = len(a)\n",
        "            data_summary.append(a)\n",
        "\n",
        "    return names, data_source, data_summary\n",
        "\n",
        "def split_to_sentences(para):\n",
        "    sents = nltk.sent_tokenize(para)   # returns list of sentences from para\n",
        "    return sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT0UExsazuwC",
        "outputId": "310c14a1-69c4-4228-c6c0-54d322c07cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "names, data_source, data_summary = get_summary_data()\n",
        "print(len(names))\n",
        "print(len(data_source))\n",
        "print(len(data_summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "1COX82xzzuwC",
        "outputId": "6018ab63-e036-46a0-eeaa-932a91ad0e2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 2012_S_270.txt - 4248 : 1362 ,"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [13:16<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a88482887d42>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m\" - \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" ,\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mextr_summ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreq_len\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# returns list of chunks summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print('--------------------------')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-3a8811aa0092>\u001b[0m in \u001b[0;36mgenerate_summary_gpu\u001b[0;34m(input_text, l)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_summary_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0minput_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   summary_ids = led.generate(input_tokenized,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                       \u001b[0mlength_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                       \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             )\n\u001b[1;32m   1610\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1612\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2907\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2909\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2910\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus_x/modeling_pegasus_x.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 )\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1629\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus_x/modeling_pegasus_x.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1503\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus_x/modeling_pegasus_x.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1340\u001b[0m                 )\n\u001b[1;32m   1341\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1343\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus_x/modeling_pegasus_x.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n\u001b[0m\u001b[1;32m    737\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/pegasus_x/modeling_pegasus_x.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# get query proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;31m# get key, value proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# `past_key_value[0].shape[2] == key_value_states.shape[1]`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# main loop to generate and save summaries of each document in the test dataset\n",
        "\n",
        "result_rouge_list = []\n",
        "result_bertscore_list = []\n",
        "\n",
        "for i in tqdm(range(2)):  # range(len(data_source))\n",
        "    name = names[i]\n",
        "    doc = data_source[i]\n",
        "    input_len = len(doc.split(\" \"))\n",
        "    req_len = get_req_len[name]\n",
        "    print(str(i) + \": \" + name +  \" - \" + str(input_len) + \" : \" + str(req_len), end = \" ,\")\n",
        "\n",
        "    extr_summ = generate_summary_gpu(doc,req_len)  # returns list of chunks summaries\n",
        "    #print('--------------------------')\n",
        "\n",
        "    if len(extr_summ.split(\" \")) > req_len:\n",
        "        extr_summ = extr_summ.split(\" \")\n",
        "        extr_summ = extr_summ[:req_len]\n",
        "        extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    print(len(data_summary[i].split(' ')),len(extr_summ.split(' ')))\n",
        "\n",
        "    rouge = Rouge()\n",
        "    result_rouge_list.append(rouge.get_scores(extr_summ, data_summary[i], avg=True))\n",
        "    bertscore = load(\"bertscore\")\n",
        "    result_bertscore_list.append(bertscore.compute(predictions=[extr_summ], references=[data_summary[i]], model_type=\"distilbert-base-uncased\"))\n",
        "    #print('---------------------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4nVMJWyzuwD",
        "outputId": "922ae736-30a7-4a61-e566-8a8fc41db0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge-1': {'r': 0.34919517102615694, 'p': 0.4248799292214358, 'f': 0.38269036953218116}, 'rouge-2': {'r': 0.17655071776181952, 'p': 0.19880821541420524, 'f': 0.1858949298444496}, 'rouge-l': {'r': 0.3137683242311009, 'p': 0.3802641557128412, 'f': 0.3432646344228572}}\n"
          ]
        }
      ],
      "source": [
        "agg_rouge_score_1 = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score_1[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYhiLgD2zuwD",
        "outputId": "22651690-c0fe-4df4-cdeb-7e0d398fdc53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'precision': 0.7688697874546051, 'recall': 0.7728851437568665, 'f1': 0.7708407342433929}\n"
          ]
        }
      ],
      "source": [
        "agg_bertscore_1 = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for i in range(len(result_bertscore_list)):\n",
        "  for metric_type in ['precision','recall','f1']:\n",
        "    agg_bertscore_1[metric_type]+=((result_bertscore_list[i][metric_type][0])/len(result_bertscore_list))\n",
        "\n",
        "print(agg_bertscore_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPKljKKAzuwD"
      },
      "source": [
        "### Testing A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr9zMDYazuwE"
      },
      "outputs": [],
      "source": [
        "def get_root_path():\n",
        "    '''\n",
        "    function to get root path of dataset\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "    path = \"/content/drive/MyDrive/ExtractiveDataset/test-data\"  # use all 50 docs for testing if using abstractive dataset for training\n",
        "    return path\n",
        "\n",
        "def get_summary_data():\n",
        "    '''\n",
        "    function to get names, documents, and summaries\n",
        "    change the path variable to the path of the dataset\n",
        "    '''\n",
        "\n",
        "    path = get_root_path() + '/judgement'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_source = []\n",
        "    names = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            p = filename.rfind(\"/\")\n",
        "            names.append(filename[p+1:])\n",
        "            a = f.read()\n",
        "            data_source.append(a)\n",
        "    path = get_root_path() + '/summary/A2'\n",
        "    all_files = glob.glob(path + \"/*.txt\")\n",
        "    data_summary = []\n",
        "    for filename in all_files:\n",
        "        with open(filename, 'r') as f:\n",
        "            a = f.read()\n",
        "            l = len(a)\n",
        "            data_summary.append(a)\n",
        "\n",
        "    return names, data_source, data_summary\n",
        "\n",
        "def split_to_sentences(para):\n",
        "    sents = nltk.sent_tokenize(para)   # returns list of sentences from para\n",
        "    return sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TchXS6wzuwE",
        "outputId": "f47ddcfc-243f-4530-cbd9-211cbd5981f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "names, data_source, data_summary = get_summary_data()\n",
        "print(len(names))\n",
        "print(len(data_source))\n",
        "print(len(data_summary))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpG0S5OMzuwE",
        "outputId": "43795dae-262a-4c9a-b6c5-cd6422b482c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 2012_S_270.txt - 4248 : 1362 ,Value of p for doc 0 is 0.3206214689265537\n"
          ]
        }
      ],
      "source": [
        "# main loop to generate and save summaries of each document in the test dataset\n",
        "\n",
        "result_rouge_list = []\n",
        "result_bertscore_list = []\n",
        "\n",
        "for i in tqdm(range(len(data_source))):\n",
        "    name = names[i]\n",
        "    doc = data_source[i]\n",
        "    input_len = len(doc.split(\" \"))\n",
        "    req_len = get_req_len[name]\n",
        "    print(str(i) + \": \" + name +  \" - \" + str(input_len) + \" : \" + str(req_len), end = \" ,\")\n",
        "\n",
        "    nested = nest_sentences(doc,512)  # returns a list of chunks with word count < 512\n",
        "    p = float(req_len/input_len)  # p is the ratio of summary length to doc length\n",
        "    print('Value of p for doc {} is {}'.format(i,p))\n",
        "\n",
        "    extr_summ = generate_summary_gpu(nested,p)  # returns list of chunks summaries\n",
        "\n",
        "    extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    if len(extr_summ.split(\" \")) > req_len:\n",
        "        extr_summ = extr_summ.split(\" \")\n",
        "        extr_summ = extr_summ[:req_len]\n",
        "        extr_summ = \" \".join(extr_summ)\n",
        "\n",
        "    print(len(data_summary[i].split(' ')),len(extr_summ.split(' ')))\n",
        "\n",
        "    rouge = Rouge()\n",
        "    result_rouge_list.append(rouge.get_scores(extr_summ, data_summary[i], avg=True))\n",
        "    bertscore = load(\"bertscore\")\n",
        "    result_bertscore_list.append(bertscore.compute(predictions=[extr_summ], references=[data_summary[i]], model_type=\"distilbert-base-uncased\"))\n",
        "    print('---------------------------------------------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgVx4PsUzuwE",
        "outputId": "7e73bf4b-0a75-4f55-e81f-94c4c543f75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge-1': {'r': 0.21187794059777082, 'p': 0.49926828337230633, 'f': 0.2935809851176972}, 'rouge-2': {'r': 0.07604486106863347, 'p': 0.20917546307120924, 'f': 0.1102924148470025}, 'rouge-l': {'r': 0.20117182810722975, 'p': 0.47589578811019456, 'f': 0.2791278810436789}}\n"
          ]
        }
      ],
      "source": [
        "agg_rouge_score_2 = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for i in range(len(result_rouge_list)):\n",
        "  for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "    for j in ['r','p','f']:\n",
        "      agg_rouge_score_2[rouge_type][j]+=(result_rouge_list[i][rouge_type][j]/len(result_rouge_list))\n",
        "\n",
        "print(agg_rouge_score_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdj49OyuzuwF",
        "outputId": "fc8c428b-4513-4f64-af77-8bb05f98c977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'precision': 0.7443345665931702, 'recall': 0.751188361644745, 'f1': 0.7473442792892456}\n"
          ]
        }
      ],
      "source": [
        "agg_bertscore_2 = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for i in range(len(result_bertscore_list)):\n",
        "  for metric_type in ['precision','recall','f1']:\n",
        "    agg_bertscore_2[metric_type]+=((result_bertscore_list[i][metric_type][0])/len(result_bertscore_list))\n",
        "\n",
        "print(agg_bertscore_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo6egCCqzuwF"
      },
      "source": [
        "###Average ROUGE score and BERTScores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CMt5fKqzuwF"
      },
      "outputs": [],
      "source": [
        "agg_rouge_score = {'rouge-1':{'r':0,'p':0,'f':0},'rouge-2':{'r':0,'p':0,'f':0},\n",
        "                   'rouge-l':{'r':0,'p':0,'f':0}}\n",
        "\n",
        "for rouge_type in ['rouge-1','rouge-2','rouge-l']:\n",
        "  for j in ['r','p','f']:\n",
        "    agg_rouge_score[rouge_type][j]=(agg_rouge_score_1[rouge_type][j]+agg_rouge_score_2[rouge_type][j])*0.5\n",
        "\n",
        "print(agg_rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Bp47qI8zuwG"
      },
      "outputs": [],
      "source": [
        "print('ROUGE Scores of A1 Golden summary:')\n",
        "print(agg_rouge_score_1)\n",
        "print()\n",
        "print('ROUGE Scores of A2 Golden summary:')\n",
        "print(agg_rouge_score_2)\n",
        "print()\n",
        "print('ROUGE Average ROUGE scores of both summaries:')\n",
        "print(agg_rouge_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TvR3COqzuwG"
      },
      "outputs": [],
      "source": [
        "agg_bertscore = {'precision':0, 'recall':0, 'f1':0}\n",
        "\n",
        "for metric_type in ['precision','recall','f1']:\n",
        "  agg_bertscore[metric_type]+=(agg_bertscore_1[metric_type]+agg_bertscore_2[metric_type])*0.5\n",
        "\n",
        "print(agg_bertscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ovjbM2zuwG"
      },
      "outputs": [],
      "source": [
        "print('BERTScores of A1 Golden summary:')\n",
        "print(agg_bertscore_1)\n",
        "print()\n",
        "print('BERTScores of A2 Golden summary:')\n",
        "print(agg_bertscore_2)\n",
        "print()\n",
        "print('Average BERTScores scores of both summaries:')\n",
        "print(agg_bertscore)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1SZznNKWaLSG",
        "yKREfDSi_FP1"
      ],
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "000b810d3dad49a497bdd6916a5db059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06421b7e4d49473cb23cbd783a9a41b4",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4e66587fc34a1399401c8a0ebe9521",
            "value": " 1.02G/1.02G [00:03&lt;00:00, 182MB/s]"
          }
        },
        "00d7daa906934af78a03d3c2f267a531": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "013956f03f2a43fdb7376afc579fa38f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019b2a2008e8431da355e7374b7a1c66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02fa1b0898eb45709ee27f0278d4f32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e4b52e88b44bebbb0a6280612f189b",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc7b5e995b0474aa5d1536f3808d865",
            "value": " 6.60M/6.60M [00:00&lt;00:00, 25.2MB/s]"
          }
        },
        "0373cc5ba6384ab4998cbc3642f0963d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f455acf62364fc1909e19e0d79a7c72",
            "placeholder": "​",
            "style": "IPY_MODEL_df45b13661434c9d931b42d7dda1a394",
            "value": " 440M/440M [00:02&lt;00:00, 192MB/s]"
          }
        },
        "039f90b899ca47c7a72b44c05aa3d231": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b0bf06a805f4828a024f3869b7711a7",
            "placeholder": "​",
            "style": "IPY_MODEL_5164f226cc4d43fdb89ae5d529a43712",
            "value": " 1/1 [00:18&lt;00:00, 18.32s/it, v_num=0]"
          }
        },
        "0405e02d9a6a45e8aa4c205f8d5dbc82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04631b1105974b6fb5005278c6458f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0569025b87584f3baa164433f54fc213": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c9bbf29ed8423193e3266b870825ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee9a1214315453eb0457b89362582ee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e85567675a74fcdaaf59bdc51f63b18",
            "value": 1
          }
        },
        "06421b7e4d49473cb23cbd783a9a41b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0955b13fe49145de8440afad6d6c448c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b19d78b971b4980bf2cea71f668e908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f748bbb050494f68a00d3681c9594c0b",
            "placeholder": "​",
            "style": "IPY_MODEL_a167fe71d31249169743e4f2f90e225b",
            "value": " 1/1 [00:00&lt;00:00, 12.03it/s]"
          }
        },
        "0bf4795eef79446c996ea0a7cbf12fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c57d803d2f473db134997f01269445",
            "placeholder": "​",
            "style": "IPY_MODEL_cc29d7bc0e42486e92836567a865a9b7",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0c87889469fd436696be18ec99057847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33caefba554649e5ad6970d14385a690",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a85bad7ce0584070b4365e3bd60c65bb",
            "value": 456318
          }
        },
        "0d2c89406deb426596d6b79ed13f34fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e85567675a74fcdaaf59bdc51f63b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f03962741d5463a9dd42dbd51d5fba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12520932ac784f13aec2bc5452370880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12a256b02a234ccaac1fda36ff120f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18dccbc2d8d8436884adcbd2e48710aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac607e248ac44dd880e6c6af4129eee",
            "placeholder": "​",
            "style": "IPY_MODEL_c7b3df5601044215b18950f2a4b69b00",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "18e2fee7561f4ad7983fefaf53ea6848": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19dc2b9cf8f64ec5a2265bc8eb1bcaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0569025b87584f3baa164433f54fc213",
            "max": 6603131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b28477acd34b441eb80bbcb8feb3c0ca",
            "value": 6603131
          }
        },
        "19e6a261c3c841bd98c51285c586d7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1be19a08e990434aa0a4d8aa4bb636c8",
              "IPY_MODEL_4fdce4b2e1e0447abafe75b5b7b3ae9d",
              "IPY_MODEL_039f90b899ca47c7a72b44c05aa3d231"
            ],
            "layout": "IPY_MODEL_e2280b37404748ac8ee987f752169a5b"
          }
        },
        "1ab14a8461954111b095d85f76f4b6b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be19a08e990434aa0a4d8aa4bb636c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b84d53ebde12442da0dfd6d855c08e32",
            "placeholder": "​",
            "style": "IPY_MODEL_d7270698670c4186ab804d5a35d2d37c",
            "value": "Epoch 2: 100%"
          }
        },
        "1ceaddc142b44ae0be729c791361c63b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d633d5c31164331a252b7d6c4eefd0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e21df12620b4339a3d415d9104c3254": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40716c63ca234059bbb8f0fb56cc4e1d",
              "IPY_MODEL_05c9bbf29ed8423193e3266b870825ac",
              "IPY_MODEL_0b19d78b971b4980bf2cea71f668e908"
            ],
            "layout": "IPY_MODEL_ec820f74db204d41854f190d024d43d8"
          }
        },
        "2517f3ba997e4cdba09838affb1d6137": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2579ae4c3ccc4ae5ae0264dfc861e6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2845e9abda8d4b82a7095049d04e5b83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28fe7739ee6c40629dcc46b7c0a566db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_922762114c3b4919bd0d9f4589bf8560",
              "IPY_MODEL_f76cf01f6a974e21ad3fbc0def764609",
              "IPY_MODEL_49baa69beb5745ecb36ab37f4caf2c41"
            ],
            "layout": "IPY_MODEL_5b89412edc9f456cb11cf5ec03d9fc92"
          }
        },
        "2b9e6c69b36c4e2180be94fcc663f9e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c216fde7be0494592363138d76eeb74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e15ef89283a41548619ea1c8e4afcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f455acf62364fc1909e19e0d79a7c72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "319744f931c9494094e061995c2bf646": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ebd380e9244b2e87715d1a8e6fb2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1d28e620505477ebf607e590aff5b61",
            "placeholder": "​",
            "style": "IPY_MODEL_04631b1105974b6fb5005278c6458f59",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "332dbb89aea04ca2ab78e6bbf0c98a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc1abee02d7044e6a7cf9b159750cfb4",
            "placeholder": "​",
            "style": "IPY_MODEL_4bd030bf0c494ac0aa686adcd1e4f924",
            "value": " 262/262 [00:00&lt;00:00, 7.14kB/s]"
          }
        },
        "33caefba554649e5ad6970d14385a690": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343bf943bedf498bb9f6e252c10eab6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_658f6b1eeb3d4f40b9e9ef8281d24918",
              "IPY_MODEL_ed2b35ef568b421486fb0c5fdff588cf",
              "IPY_MODEL_957685d3befc48af85f7d159a701afa3"
            ],
            "layout": "IPY_MODEL_9998d239f89445d0941ea73d883601f7"
          }
        },
        "358facabc8744a668fd1ac57a6d98653": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36837c1a41694878b3b0b6233aad4250": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3731eaa44eb64f2b9a0e0acda7406c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "390d0f9dc0284726ac9ee3bebb5904d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3adc7241b621413f884aeaffac53385c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b3cdd764f92446cbfe1be1a1190d724": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_013956f03f2a43fdb7376afc579fa38f",
            "placeholder": "​",
            "style": "IPY_MODEL_d07e8da39ebb4d01b6cc07c6195d6f3b",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "3d4e66587fc34a1399401c8a0ebe9521": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40625ba561334f1d8cea34b98683a0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b9e6c69b36c4e2180be94fcc663f9e9",
            "placeholder": "​",
            "style": "IPY_MODEL_844b32fc38394caeae3340ad83f3f24a",
            "value": " 1/1 [00:00&lt;00:00, 11.62it/s]"
          }
        },
        "40716c63ca234059bbb8f0fb56cc4e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019b2a2008e8431da355e7374b7a1c66",
            "placeholder": "​",
            "style": "IPY_MODEL_d093f1d7d3544bc0b359195ed090f4f4",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "4397ca8104d141409052dacd05d59817": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43eeb3a43f5c4cee8598ba177653e388": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43fd64aefdea498f9e426a42b5ed7f86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c9e4ecec3345f5a1055fe58345fdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95fa349725354d5284ffe4ad9b474c95",
            "placeholder": "​",
            "style": "IPY_MODEL_53080f809c5e4d048ff7f4593cf8b66c",
            "value": " 1.77k/1.77k [00:00&lt;00:00, 20.8kB/s]"
          }
        },
        "48e91a57a23242039a6d9065b95cc0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb3aa40c57814ea6aae1463fafec5da7",
            "placeholder": "​",
            "style": "IPY_MODEL_12520932ac784f13aec2bc5452370880",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "49baa69beb5745ecb36ab37f4caf2c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c26c466e871d4f89be32427449ce91bc",
            "placeholder": "​",
            "style": "IPY_MODEL_5bd7f71a30f34332832d0681d62595db",
            "value": " 1.91M/1.91M [00:00&lt;00:00, 18.5MB/s]"
          }
        },
        "49fb00072185411e85df878c40c8cf8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d140eca1064fb0b8eaec92df9e4b89",
            "placeholder": "​",
            "style": "IPY_MODEL_ee89d969984c4be2887745a7bd0a105d",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "4a842a2468ca402fb82bd3f63853c261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4397ca8104d141409052dacd05d59817",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6745552a8cbc432c8af7f4daf9081af7",
            "value": 1
          }
        },
        "4bd030bf0c494ac0aa686adcd1e4f924": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c70f0e494d84fef8bb9a833a831695b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d53aa2de03d4812a5eb1fc473e6a60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d18c4bf97964275ace29ba6a5a38bf6",
            "max": 1089293365,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8498a075b2142eca7886db9ebff2e6a",
            "value": 1089293365
          }
        },
        "4ede9efd653148759649c3c6b50ef0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bf4795eef79446c996ea0a7cbf12fef",
              "IPY_MODEL_d5cea8e955c2440f928e464008069bbf",
              "IPY_MODEL_6cb190e2fef541ef817e185b674edb58"
            ],
            "layout": "IPY_MODEL_1ceaddc142b44ae0be729c791361c63b"
          }
        },
        "4fdce4b2e1e0447abafe75b5b7b3ae9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319744f931c9494094e061995c2bf646",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a250b9f9b4a648f7b75c8730e0d45027",
            "value": 1
          }
        },
        "5164f226cc4d43fdb89ae5d529a43712": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "529bfa606f2d4a96ac274173011a5516": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_628bc170cee8485d944f3dffae0ab0a4",
            "placeholder": "​",
            "style": "IPY_MODEL_757c9065de5a4da8aa6d7b1effa2d8c2",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "53080f809c5e4d048ff7f4593cf8b66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "545072ee19ca498d883dba244a8ff96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0dc6ab7b86d4c179cd815d288803c7d",
              "IPY_MODEL_9a2747a5d5934d14a962f216fbd6574c",
              "IPY_MODEL_f034c1ffe4f6463b8ba1df6321a9feef"
            ],
            "layout": "IPY_MODEL_8f5624fe417740c5b399b493e993c46a"
          }
        },
        "5b89412edc9f456cb11cf5ec03d9fc92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bd7f71a30f34332832d0681d62595db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cacdf31d03d457db7d0235eb5a8c70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce316b9263a143f8ab64e79ece81de26",
            "placeholder": "​",
            "style": "IPY_MODEL_dbb74dd0d23c42668e9f20ba60586134",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "5d0119f4365340ffba67f216640048d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5de18f5e700e4905a4a024d4e0acc06f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6707ee340a48bdbd10819d2254084d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa26c1f786a48a7a2aa9f9785caadf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "628bc170cee8485d944f3dffae0ab0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b113271b5842a0b5c5a02d8cc66622": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658f6b1eeb3d4f40b9e9ef8281d24918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c216fde7be0494592363138d76eeb74",
            "placeholder": "​",
            "style": "IPY_MODEL_e2316d64cf0e4b30aaa0f1badfd65a9d",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "6745552a8cbc432c8af7f4daf9081af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "678fe89ab1ea4d25bf8f1f74d41e714f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6825ff6cf0854906b3ee6a3f3a6afdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "683bf52e2f614a0aa5ba4b7eca356c47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b257af763f4ef991b69f40437d29a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "690d77dfc6054fe597541addec540e61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0bf06a805f4828a024f3869b7711a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2b0a6872c04132844f481bbf7b9562": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cb190e2fef541ef817e185b674edb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62b113271b5842a0b5c5a02d8cc66622",
            "placeholder": "​",
            "style": "IPY_MODEL_9a2f344f94b342a5b87385c840419c5b",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 23.2kB/s]"
          }
        },
        "70194ae49b374f0996cde1005204fcde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abade9d7576249ed90f502c079eb19e6",
            "placeholder": "​",
            "style": "IPY_MODEL_678fe89ab1ea4d25bf8f1f74d41e714f",
            "value": " 1.09G/1.09G [00:14&lt;00:00, 137MB/s]"
          }
        },
        "701c2582aec1435ea0d8d7b917dfefeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7248a75b3b28464cb3d337282670bd21",
              "IPY_MODEL_9d2102b370e44e1a952de2c02fd878ef",
              "IPY_MODEL_9622f0a288794e86823d7767b80f0306"
            ],
            "layout": "IPY_MODEL_ffd323f93ca4416b9fe962faf3e8640c"
          }
        },
        "7133d67addc4490dbed7629c29e7f51f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7248a75b3b28464cb3d337282670bd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36837c1a41694878b3b0b6233aad4250",
            "placeholder": "​",
            "style": "IPY_MODEL_5fa26c1f786a48a7a2aa9f9785caadf1",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "73f1b7b3fa2a4d62921f203a780f9c88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "744ac6ee7b344d9e8e411ea7c9e21244": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757c9065de5a4da8aa6d7b1effa2d8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "775ec9c39b1644c591c3e0a2e5569fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bd0e33b4d8b44f8b717a03461df597a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8011b4e04a4ad4996355d989e695cd",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd58341fdbe446db9651a18526e155f6",
            "value": 440449768
          }
        },
        "7eb836cc1b6a43b2841a288426de7550": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea2002f4e221493ea8947496d2c2f2ec",
            "placeholder": "​",
            "style": "IPY_MODEL_f3b313eecd1e44a08540f6913750ba53",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7eea1d8962c94ead9d817da6212374fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_529bfa606f2d4a96ac274173011a5516",
              "IPY_MODEL_19dc2b9cf8f64ec5a2265bc8eb1bcaad",
              "IPY_MODEL_02fa1b0898eb45709ee27f0278d4f32f"
            ],
            "layout": "IPY_MODEL_e4a387ad22094d2f9eaf1e9372699e58"
          }
        },
        "7f18fc2aee19427a8e6e73c70a23427b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8202feb9574949cda81385567d1a0732": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e4b52e88b44bebbb0a6280612f189b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "844b32fc38394caeae3340ad83f3f24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86eeefd5211c474d82482da13cf75854": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b19f0b7b0efd4f60aba2558c42452268",
              "IPY_MODEL_fd9679d97095437d9a5c68fa696cc000",
              "IPY_MODEL_47c9e4ecec3345f5a1055fe58345fdf0"
            ],
            "layout": "IPY_MODEL_5de18f5e700e4905a4a024d4e0acc06f"
          }
        },
        "8e7dc265cd6d4ccf90f19bbdc870a80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0aeadfd5ac848728660ed3ddd162253",
            "max": 262,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f79d5409fb924d41a72db28e2f677e8b",
            "value": 262
          }
        },
        "8f5624fe417740c5b399b493e993c46a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "90d140eca1064fb0b8eaec92df9e4b89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "922762114c3b4919bd0d9f4589bf8560": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_690d77dfc6054fe597541addec540e61",
            "placeholder": "​",
            "style": "IPY_MODEL_43eeb3a43f5c4cee8598ba177653e388",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "940d0566d80748cc800cd4cea51402a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "957685d3befc48af85f7d159a701afa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc9dd6d2dd6948dcbf8c9823bcbe8b8d",
            "placeholder": "​",
            "style": "IPY_MODEL_775ec9c39b1644c591c3e0a2e5569fec",
            "value": " 899k/899k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "95fa349725354d5284ffe4ad9b474c95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9622f0a288794e86823d7767b80f0306": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8202feb9574949cda81385567d1a0732",
            "placeholder": "​",
            "style": "IPY_MODEL_7f18fc2aee19427a8e6e73c70a23427b",
            "value": " 1/1 [00:00&lt;00:00,  1.74it/s]"
          }
        },
        "96549dd0c7574a25a28409b08bd57b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f859b76a8e43748e1d604ced91f09e",
            "placeholder": "​",
            "style": "IPY_MODEL_d06e3bd592774bc68a8936ede7621cd1",
            "value": " 26.0/26.0 [00:00&lt;00:00, 537B/s]"
          }
        },
        "969d2b10603a4c75b90a6711c22bd6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d733fdba81742e298d13e2f0d8fba6e",
            "placeholder": "​",
            "style": "IPY_MODEL_f4b40914eb044fb69c669b7d578d97e2",
            "value": " 456k/456k [00:00&lt;00:00, 708kB/s]"
          }
        },
        "985960bcd1074f90a3c880f7bd3d077b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "994d2c30434e417498fbdf3c288881b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b3cdd764f92446cbfe1be1a1190d724",
              "IPY_MODEL_7bd0e33b4d8b44f8b717a03461df597a",
              "IPY_MODEL_0373cc5ba6384ab4998cbc3642f0963d"
            ],
            "layout": "IPY_MODEL_2517f3ba997e4cdba09838affb1d6137"
          }
        },
        "9998d239f89445d0941ea73d883601f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2747a5d5934d14a962f216fbd6574c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d2c89406deb426596d6b79ed13f34fd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a052678115c14bad88389d02264673d7",
            "value": 1
          }
        },
        "9a2f344f94b342a5b87385c840419c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d18c4bf97964275ace29ba6a5a38bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2102b370e44e1a952de2c02fd878ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7133d67addc4490dbed7629c29e7f51f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cda793a53446445ea39cf84c861475c9",
            "value": 1
          }
        },
        "9d733fdba81742e298d13e2f0d8fba6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a052678115c14bad88389d02264673d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a167fe71d31249169743e4f2f90e225b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a250b9f9b4a648f7b75c8730e0d45027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5c4912ba0e64a6ebb536a2a9230674f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c57d803d2f473db134997f01269445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a784f6e9da5145dd88e194841b0cc091": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85bad7ce0584070b4365e3bd60c65bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9e5035720db486db1046b991c244b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68b257af763f4ef991b69f40437d29a2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2e08a4c77fe4fbb85f2f56aa0c3d39a",
            "value": 570
          }
        },
        "aac607e248ac44dd880e6c6af4129eee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abade9d7576249ed90f502c079eb19e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae885e445fd6499bb5dde2625f9595b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c70f0e494d84fef8bb9a833a831695b",
            "placeholder": "​",
            "style": "IPY_MODEL_2e15ef89283a41548619ea1c8e4afcca",
            "value": " 570/570 [00:00&lt;00:00, 32.6kB/s]"
          }
        },
        "b0aeadfd5ac848728660ed3ddd162253": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0dc6ab7b86d4c179cd815d288803c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d633d5c31164331a252b7d6c4eefd0e",
            "placeholder": "​",
            "style": "IPY_MODEL_0955b13fe49145de8440afad6d6c448c",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "b19f0b7b0efd4f60aba2558c42452268": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e2fee7561f4ad7983fefaf53ea6848",
            "placeholder": "​",
            "style": "IPY_MODEL_d6bad2eb6402469abf58a65dd32ad397",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "b1bd0959a55d42978b7842e0b5efba44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eb836cc1b6a43b2841a288426de7550",
              "IPY_MODEL_a9e5035720db486db1046b991c244b9a",
              "IPY_MODEL_ae885e445fd6499bb5dde2625f9595b9"
            ],
            "layout": "IPY_MODEL_2579ae4c3ccc4ae5ae0264dfc861e6c3"
          }
        },
        "b1d28e620505477ebf607e590aff5b61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28477acd34b441eb80bbcb8feb3c0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b42675dc45254a1ea754c73b5baa3bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18dccbc2d8d8436884adcbd2e48710aa",
              "IPY_MODEL_b9e86985ba554a978d03e0319827dfaf",
              "IPY_MODEL_f799ed8f0f75465697e23f2382458d9a"
            ],
            "layout": "IPY_MODEL_cc6ee55f7db7488eb651be4a03f14376"
          }
        },
        "b5f63014d64c4e2cad87bf54742b85c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48e91a57a23242039a6d9065b95cc0cc",
              "IPY_MODEL_0c87889469fd436696be18ec99057847",
              "IPY_MODEL_969d2b10603a4c75b90a6711c22bd6a6"
            ],
            "layout": "IPY_MODEL_43fd64aefdea498f9e426a42b5ed7f86"
          }
        },
        "b84d53ebde12442da0dfd6d855c08e32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8af7e2cd8cf4c398718bf0c0db926c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc87999a860c495fa2ec583bd8d76fae",
              "IPY_MODEL_8e7dc265cd6d4ccf90f19bbdc870a80d",
              "IPY_MODEL_332dbb89aea04ca2ab78e6bbf0c98a48"
            ],
            "layout": "IPY_MODEL_c862903d51de4c0ebfaf162d43ae5d63"
          }
        },
        "b9e86985ba554a978d03e0319827dfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2845e9abda8d4b82a7095049d04e5b83",
            "max": 2018,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12a256b02a234ccaac1fda36ff120f90",
            "value": 2018
          }
        },
        "ba31edf28a624daa933aa05ec239cdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31ebd380e9244b2e87715d1a8e6fb2b4",
              "IPY_MODEL_4a842a2468ca402fb82bd3f63853c261",
              "IPY_MODEL_40625ba561334f1d8cea34b98683a0c0"
            ],
            "layout": "IPY_MODEL_c5781e6a87f848689679e41b2e1f7600"
          }
        },
        "bd58341fdbe446db9651a18526e155f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c26c466e871d4f89be32427449ce91bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ef15bf4f85440bb6279c8ad82b9079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0405e02d9a6a45e8aa4c205f8d5dbc82",
            "max": 1488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9d34047162a49fea38b229c4eb16f8c",
            "value": 1488
          }
        },
        "c5781e6a87f848689679e41b2e1f7600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c7b3df5601044215b18950f2a4b69b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c825b72521534d1e99c88ef88aed53e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e6707ee340a48bdbd10819d2254084d",
            "placeholder": "​",
            "style": "IPY_MODEL_940d0566d80748cc800cd4cea51402a8",
            "value": " 1.49k/1.49k [00:00&lt;00:00, 22.0kB/s]"
          }
        },
        "c862903d51de4c0ebfaf162d43ae5d63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cadddd3f7fe04f3984c5e4cc771ec9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd64d8fadf5e41b2a1d5aeaa3c258f40",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0f9751927f24605b94cd4d14b95cfea",
            "value": 26
          }
        },
        "cb3aa40c57814ea6aae1463fafec5da7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1abee02d7044e6a7cf9b159750cfb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc29d7bc0e42486e92836567a865a9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc6ee55f7db7488eb651be4a03f14376": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc87999a860c495fa2ec583bd8d76fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a784f6e9da5145dd88e194841b0cc091",
            "placeholder": "​",
            "style": "IPY_MODEL_cdc7c95db9ce41dc8385c6bfaa645dc1",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "cc9dd6d2dd6948dcbf8c9823bcbe8b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd373f434ab7464fbafb9381aa7f1da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cda793a53446445ea39cf84c861475c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdc7c95db9ce41dc8385c6bfaa645dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce316b9263a143f8ab64e79ece81de26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3d7e7c597c44209a10da8e10e643d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15b069413c442b7975c09e9cfe97392",
            "max": 1018571383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd373f434ab7464fbafb9381aa7f1da4",
            "value": 1018571383
          }
        },
        "cf8011b4e04a4ad4996355d989e695cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d06e3bd592774bc68a8936ede7621cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d07e8da39ebb4d01b6cc07c6195d6f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d093f1d7d3544bc0b359195ed090f4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2e08a4c77fe4fbb85f2f56aa0c3d39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2fd1e17e32a46739bd9192f26084c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaa525034a1d45979f4aca4017ae25dd",
              "IPY_MODEL_c2ef15bf4f85440bb6279c8ad82b9079",
              "IPY_MODEL_c825b72521534d1e99c88ef88aed53e1"
            ],
            "layout": "IPY_MODEL_d3e554a1bb7a4a22bd77fc055aa7587c"
          }
        },
        "d3d805b24ef840798f9807d1a8055d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49fb00072185411e85df878c40c8cf8e",
              "IPY_MODEL_4d53aa2de03d4812a5eb1fc473e6a60c",
              "IPY_MODEL_70194ae49b374f0996cde1005204fcde"
            ],
            "layout": "IPY_MODEL_744ac6ee7b344d9e8e411ea7c9e21244"
          }
        },
        "d3e554a1bb7a4a22bd77fc055aa7587c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5cea8e955c2440f928e464008069bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f1b7b3fa2a4d62921f203a780f9c88",
            "max": 1628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6825ff6cf0854906b3ee6a3f3a6afdec",
            "value": 1628
          }
        },
        "d6bad2eb6402469abf58a65dd32ad397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6c045ef29eb45bcbc4355e512b986af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7270698670c4186ab804d5a35d2d37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7a281975ec74980bcb5c8a4e2ca0f20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8498a075b2142eca7886db9ebff2e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9d34047162a49fea38b229c4eb16f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbb74dd0d23c42668e9f20ba60586134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbc7b5e995b0474aa5d1536f3808d865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deb92ad15c4c403e823118c6e3571bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dee9a1214315453eb0457b89362582ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df45b13661434c9d931b42d7dda1a394": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0f9751927f24605b94cd4d14b95cfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e15b069413c442b7975c09e9cfe97392": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2280b37404748ac8ee987f752169a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e2316d64cf0e4b30aaa0f1badfd65a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4a387ad22094d2f9eaf1e9372699e58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f0810f826648c2833d107811c7b89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3d16a5f58e84374a8a7440b754035be",
              "IPY_MODEL_cadddd3f7fe04f3984c5e4cc771ec9c7",
              "IPY_MODEL_96549dd0c7574a25a28409b08bd57b5b"
            ],
            "layout": "IPY_MODEL_d6c045ef29eb45bcbc4355e512b986af"
          }
        },
        "e7f859b76a8e43748e1d604ced91f09e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2002f4e221493ea8947496d2c2f2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa525034a1d45979f4aca4017ae25dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb565d2920134f82af21837a6578d473",
            "placeholder": "​",
            "style": "IPY_MODEL_5d0119f4365340ffba67f216640048d7",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ec820f74db204d41854f190d024d43d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "ed2b35ef568b421486fb0c5fdff588cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f03962741d5463a9dd42dbd51d5fba8",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_390d0f9dc0284726ac9ee3bebb5904d1",
            "value": 898822
          }
        },
        "ee89d969984c4be2887745a7bd0a105d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f034c1ffe4f6463b8ba1df6321a9feef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3adc7241b621413f884aeaffac53385c",
            "placeholder": "​",
            "style": "IPY_MODEL_358facabc8744a668fd1ac57a6d98653",
            "value": " 1/1 [00:00&lt;00:00, 10.56it/s]"
          }
        },
        "f3b313eecd1e44a08540f6913750ba53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3d16a5f58e84374a8a7440b754035be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683bf52e2f614a0aa5ba4b7eca356c47",
            "placeholder": "​",
            "style": "IPY_MODEL_985960bcd1074f90a3c880f7bd3d077b",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "f4b40914eb044fb69c669b7d578d97e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f748bbb050494f68a00d3681c9594c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f76cf01f6a974e21ad3fbc0def764609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7a281975ec74980bcb5c8a4e2ca0f20",
            "max": 1912529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b2b0a6872c04132844f481bbf7b9562",
            "value": 1912529
          }
        },
        "f799ed8f0f75465697e23f2382458d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00d7daa906934af78a03d3c2f267a531",
            "placeholder": "​",
            "style": "IPY_MODEL_deb92ad15c4c403e823118c6e3571bea",
            "value": " 2.02k/2.02k [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "f79d5409fb924d41a72db28e2f677e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb565d2920134f82af21837a6578d473": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd64d8fadf5e41b2a1d5aeaa3c258f40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9679d97095437d9a5c68fa696cc000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ab14a8461954111b095d85f76f4b6b5",
            "max": 1766,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3731eaa44eb64f2b9a0e0acda7406c4a",
            "value": 1766
          }
        },
        "fdc7db217c654a07a59594eb7d29c9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cacdf31d03d457db7d0235eb5a8c70b",
              "IPY_MODEL_ce3d7e7c597c44209a10da8e10e643d3",
              "IPY_MODEL_000b810d3dad49a497bdd6916a5db059"
            ],
            "layout": "IPY_MODEL_a5c4912ba0e64a6ebb536a2a9230674f"
          }
        },
        "ffd323f93ca4416b9fe962faf3e8640c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "00f9149652ab4aefbc318d606d904f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bba55743c144ea1a7b8390f56fb852b",
              "IPY_MODEL_33526fc4e6ba49f5a6a7b9ada16da219",
              "IPY_MODEL_a939cb5f93224651b5728591547ae017"
            ],
            "layout": "IPY_MODEL_828ad65284374a52add02407a31443a9"
          }
        },
        "6bba55743c144ea1a7b8390f56fb852b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5103e240d3474ad88d4f000a85f4714a",
            "placeholder": "​",
            "style": "IPY_MODEL_24fafb7f362246fea8d6000c8ce42826",
            "value": "Downloading builder script: 100%"
          }
        },
        "33526fc4e6ba49f5a6a7b9ada16da219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feab39eaf5ce481f8484e0918d785fa5",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97e279d486bb4d0bae7bb10b4c6313ec",
            "value": 6270
          }
        },
        "a939cb5f93224651b5728591547ae017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219210896bc74b8786a8f520ab7a1c3c",
            "placeholder": "​",
            "style": "IPY_MODEL_9be2e04902bf4a3e8df73fb24a16df9c",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 124kB/s]"
          }
        },
        "828ad65284374a52add02407a31443a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5103e240d3474ad88d4f000a85f4714a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24fafb7f362246fea8d6000c8ce42826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feab39eaf5ce481f8484e0918d785fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97e279d486bb4d0bae7bb10b4c6313ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "219210896bc74b8786a8f520ab7a1c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9be2e04902bf4a3e8df73fb24a16df9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}